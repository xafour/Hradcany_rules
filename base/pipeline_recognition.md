# Recognition Pipeline - Projekt HradÄany

**Tags:** `#pipeline` `#recognition` `#zlatÃ½-standard`  
**Verze:** 2.0.1  
**Datum:** 2026-01-14  
**Status:** Active - Production Reference

---

## ğŸ¯ ÃšÄŒEL

Recognition pipeline je hlavnÃ­ souÄÃ¡st systÃ©mu HradÄany, kterÃ¡ automaticky identifikuje poÅ¡tovnÃ­ znÃ¡mky ze skenÅ¯ nebo fotografiÃ­. SystÃ©m pÅ™ijÃ­mÃ¡ jako vstup obrÃ¡zek znÃ¡mky (sken nebo fotografie) a vracÃ­ seznam nejpodobnÄ›jÅ¡Ã­ch kandidÃ¡tÅ¯ z referenÄnÃ­ databÃ¡ze Ground Truth. KaÅ¾dÃ½ kandidÃ¡t je pÅ™esnÄ› urÄen kombinacÃ­ tiskovÃ© desky (TD) a znÃ¡mkovÃ©ho pole (ZP), spoleÄnÄ› se statistikami podobnosti.

Pipeline Å™eÅ¡Ã­ zÃ¡kladnÃ­ problÃ©m variability vstupnÃ­ch dat. UÅ¾ivatelskÃ© skeny se liÅ¡Ã­ v kvalitÄ›, rozliÅ¡enÃ­, natoÄenÃ­ a perspektivÄ›. ZnÃ¡mka mÅ¯Å¾e bÃ½t vyfocena z Ãºhlu, mÃ­t rÅ¯znÃ© osvÄ›tlenÃ­ nebo bÃ½t ÄÃ¡steÄnÄ› zakryta. Pipeline musÃ­ tyto variace normalizovat do jednotnÃ©ho formÃ¡tu, ze kterÃ©ho lze spolehlivÄ› extrahovat charakteristickÃ© rysy pro porovnÃ¡nÃ­ s referenÄnÃ­mi znÃ¡mkami.

CelÃ½ proces je navrÅ¾en jako deterministickÃ½ - stejnÃ½ vstup vÅ¾dy produkuje stejnÃ½ vÃ½stup. To je kritickÃ© pro reprodukovatelnost vÃ½sledkÅ¯ a moÅ¾nost systematickÃ©ho testovÃ¡nÃ­ pÅ™esnosti systÃ©mu. DeterministickÃ© chovÃ¡nÃ­ zajiÅ¡Å¥ujeme fixnÃ­m seedem pro projekÄnÃ­ hlavu embedding modelu, konstantnÃ­mi parametry pro warp transformaci a L2 normalizacÃ­ vÅ¡ech embedding vektorÅ¯.

Tento dokument popisuje zlatÃ½ standard recognition pipeline tak, jak je implementovÃ¡n v produkÄnÃ­m programu `recognize_stamp.py` verze 3.2.0. Je to referenÄnÃ­ dokumentace pro vÅ¡echny ÄÃ¡sti systÃ©mu kterÃ© potÅ™ebujÃ­ rozpoznÃ¡vat znÃ¡mky. NovÃ© implementace (napÅ™Ã­klad webovÃ© API nebo batch processing nÃ¡stroje) musÃ­ dodrÅ¾et workflow popsanÃ© v tomto dokumentu aby zajistily kompatibilitu vÃ½sledkÅ¯.

---

## ğŸ“‹ PÅ˜EHLED

Recognition pipeline se sklÃ¡dÃ¡ ze ÄtrnÃ¡cti fÃ¡zÃ­ kterÃ© na sebe lineÃ¡rnÄ› navazujÃ­. PrvnÃ­ch devÄ›t fÃ¡zÃ­ tvoÅ™Ã­ jÃ¡dro rozpoznÃ¡vacÃ­ho procesu - jsou povinnÃ© a musÃ­ bÃ½t dodrÅ¾eny ve vÅ¡ech implementacÃ­ch. FÃ¡ze deset aÅ¾ ÄtrnÃ¡ct jsou volitelnÃ© pomocnÃ© funkce specifickÃ© pro jednotlivÃ© use cases.

**Core recognition workflow (fÃ¡ze 1-9):**
Tyto fÃ¡ze implementujÃ­ samotnÃ½ rozpoznÃ¡vacÃ­ algoritmus. ZaÄÃ­nÃ¡me naÄtenÃ­m konfigurace z databÃ¡ze, inicializacÃ­ embedding modelu a detekcÃ­ rÃ¡meÄku znÃ¡mky pomocÃ­ YOLO. NÃ¡sleduje perspektivnÃ­ transformace (warp) znÃ¡mky do standardizovanÃ©ho formÃ¡tu 1300Ã—1100 pixelÅ¯. Pokud uÅ¾ivatel nezadal typ znÃ¡mky (denomination), systÃ©m ho automaticky detekuje pomocÃ­ multi-phase algoritmu kterÃ½ kombinuje embedding similarity, OCR a HSV color matching. Po urÄenÃ­ typu znÃ¡mky naÄteme definice vÃ½Å™ezÅ¯ (crops) specifickÃ© pro danou kresbu, vyÅ™Ã­zneme tyto oblasti a vypoÄÃ­tÃ¡me pro kaÅ¾dou 512-dimenzionÃ¡lnÃ­ embedding vektor. Tyto query embeddings pak porovnÃ¡me s referenÄnÃ­mi embeddingy v databÃ¡zi pomocÃ­ cosine similarity, agregujeme vÃ½sledky po kandidÃ¡tech (TD + ZP kombinace) a seÅ™adÃ­me je podle prÅ¯mÄ›rnÃ© podobnosti.

**VolitelnÃ© pomocnÃ© funkce (fÃ¡ze 10-14):**
Tyto fÃ¡ze nejsou souÄÃ¡stÃ­ zlatÃ©ho standardu pro recognition. SlouÅ¾Ã­ pro specifickÃ© use cases programu `recognize_stamp.py` - napÅ™Ã­klad vytvoÅ™enÃ­ zÃ¡znamu v databÃ¡zi (fÃ¡ze 10), naÄtenÃ­ poznÃ¡mek z .notes.json souboru (fÃ¡ze 11), vÃ½pis vÃ½sledkÅ¯ (fÃ¡ze 12), validace proti oÄekÃ¡vanÃ©mu vÃ½sledku pÅ™i testovÃ¡nÃ­ (fÃ¡ze 13) a vytvoÅ™enÃ­ vizuÃ¡lnÃ­ mozaiky pro kontrolu (fÃ¡ze 14). Tyto fÃ¡ze mÅ¯Å¾ou bÃ½t v jinÃ½ch implementacÃ­ch vynechÃ¡ny nebo nahrazeny podle potÅ™eby.

KlÃ­Äovou charakteristikou pipeline je hybrid pÅ™Ã­stup k detekci rÃ¡meÄku (fÃ¡ze 3) - systÃ©m nejdÅ™Ã­v zkusÃ­ naÄÃ­st jiÅ¾ detekovanÃ½ quad z databÃ¡zovÃ© cache, coÅ¾ je velmi rychlÃ© (Å™Ã¡dovÄ› milisekundy). Teprve pokud quad v cache nenÃ­, spustÃ­ se YOLO inference kterÃ¡ je podstatnÄ› pomalejÅ¡Ã­ (Å™Ã¡dovÄ› stovky milisekund). Tento pÅ™Ã­stup vÃ½raznÄ› zrychluje opakovanÃ© zpracovÃ¡nÃ­ stejnÃ½ch skenÅ¯, coÅ¾ je bÄ›Å¾nÃ½ scÃ©nÃ¡Å™ pÅ™i testovÃ¡nÃ­ a ladÄ›nÃ­ systÃ©mu.

---

## ğŸ”„ HLAVNÃ WORKFLOW

### FÃ¡ze 1: NaÄtenÃ­ konfigurace z databÃ¡ze

V prvnÃ­ fÃ¡zi pipeline naÄÃ­tÃ¡ z databÃ¡ze zÃ¡kladnÃ­ konfiguraci potÅ™ebnou pro rozpoznÃ¡vÃ¡nÃ­. KonkrÃ©tnÄ› jde o informace o YOLO modelu pouÅ¾itÃ©m pro detekci rÃ¡meÄkÅ¯ a o embedding modelu vÄetnÄ› projekÄnÃ­ hlavy. Tyto informace jsou uloÅ¾eny v tabulkÃ¡ch `model_registry` a `model_embed_head`.

NaÄtenÃ­ konfigurace z databÃ¡ze mÃ­sto hardcoded hodnot v kÃ³du umoÅ¾Åˆuje verzovÃ¡nÃ­ modelÅ¯. KdyÅ¾ trÃ©nujeme novÃ½ YOLO model nebo mÄ›nÃ­me architekturu embedding sÃ­tÄ›, staÄÃ­ pÅ™idat novÃ½ zÃ¡znam do databÃ¡ze a vÅ¡echny bÄ›Å¾Ã­cÃ­ instance pipeline automaticky pouÅ¾ijÃ­ novou verzi. To je kritickÃ© pro konzistenci vÃ½sledkÅ¯ - vÅ¡echny embeddings v databÃ¡zi musÃ­ bÃ½t vypoÄÃ­tanÃ© stejnÃ½m modelem se stejnou projekÄnÃ­ hlavou.

DatabÃ¡zovÃ½ zÃ¡znam obsahuje SHA256 hash souboru s modelem, coÅ¾ umoÅ¾Åˆuje verifikovat Å¾e pouÅ¾Ã­vÃ¡me sprÃ¡vnou verzi. Pro embedding model je navÃ­c uloÅ¾en seed pouÅ¾itÃ½ pro inicializaci projekÄnÃ­ hlavy (typicky 12345). Tento seed musÃ­ bÃ½t identickÃ½ pÅ™i vÃ½poÄtu referenÄnÃ­ch embeddingÅ¯ i query embeddingÅ¯, jinak by nebyly embeddings porovnatelnÃ©.

**TechnickÃ© detaily:**
```sql
-- NaÄtenÃ­ informacÃ­ o YOLO modelu
SELECT id, tag, sha256 FROM model_registry WHERE id = 1;

-- NaÄtenÃ­ informacÃ­ o embedding modelu vÄetnÄ› projekÄnÃ­ hlavy
SELECT m.id, m.tag, m.sha256, h.seed, h.head_sha256
FROM model_registry m
JOIN model_embed_head h ON m.id = h.model_id
WHERE m.id = 3;
```

### FÃ¡ze 2: Inicializace embedding modelu

DruhÃ¡ fÃ¡ze inicializuje embedding model kterÃ½ bude pouÅ¾it pro vÃ½poÄet query embeddingÅ¯. KonkrÃ©tnÄ› jde o RealEncoder - wrapper kolem ResNet50 kterÃ½ mÃ¡ zabudovanÃ© preprocessing (konverze BGRâ†’RGB, resize na 224Ã—224, normalizace do rozsahu [0,1]) a deterministickou projekÄnÃ­ hlavu pro redukci dimenze z 2048D na 512D.

RealEncoder je kritickÃ¡ komponenta protoÅ¾e musÃ­ bÃ½t naprosto identickÃ½ s tÃ­m kterÃ½ byl pouÅ¾it pro vÃ½poÄet referenÄnÃ­ch embeddingÅ¯ uloÅ¾enÃ½ch v databÃ¡zi. JakÃ½koliv rozdÃ­l v preprocessing (napÅ™Ã­klad jinÃ¡ normalizace) nebo v projekÄnÃ­ hlavÄ› (jinÃ½ seed) by vedl k neporovnatelnÃ½m embeddingÅ¯m a recognition by selhal.

ProjekÄnÃ­ hlava je inicializovÃ¡na z .pth souboru kterÃ½ obsahuje natrÃ©novanÃ© vÃ¡hy neuronovÃ© sÃ­tÄ›. PÅ™ed inicializacÃ­ se nastavÃ­ fixnÃ­ seed (typicky 12345) aby byla hlava deterministickÃ¡ - stejnÃ½ vstup vÅ¾dy produkuje stejnÃ½ vÃ½stup. Toto je dÅ¯leÅ¾itÃ© protoÅ¾e projekÄnÃ­ hlava obsahuje random inicializaci nÄ›kterÃ½ch vrstev a bez fixnÃ­ho seedu by kaÅ¾dÃ¡ instance modelu mÄ›la jinÃ© vÃ¡hy.

Po inicializaci se model pÅ™epne do evaluation mÃ³du (`model.eval()`) aby se vypnuly vrstvy kterÃ© se chovajÃ­ jinak bÄ›hem trÃ©novÃ¡nÃ­ (napÅ™Ã­klad dropout nebo batch normalization). VÅ¡echny vÃ½poÄty probÃ­hajÃ­ s `torch.no_grad()` aby se nealokovala pamÄ›Å¥ pro gradienty - pÅ™i inference je nepotÅ™ebujeme.

**TechnickÃ© detaily:**
```python
from common.embedding_utils import RealEncoder

# Inicializace RealEncoder s deterministickou hlavou
encoder = RealEncoder(
    model_path=model_file,        # ResNet50 weights
    head_path=head_file,          # ProjekÄnÃ­ hlava .pth
    seed=12345,                   # FixnÃ­ seed pro determinismus
    device='cpu'                  # CPU inference (GPU nenÃ­ nutnÃ©)
)

# Model je automaticky v eval() mÃ³du
# VÅ¡echny vÃ½poÄty probÃ­hajÃ­ v torch.no_grad() context
```

### FÃ¡ze 3: Detekce rÃ¡meÄku znÃ¡mky (YOLO hybrid approach)

TÅ™etÃ­ fÃ¡ze detekuje ÄtyÅ™i rohovÃ© body rÃ¡meÄku znÃ¡mky v pÅ¯vodnÃ­m obrÃ¡zku. Tento quad (ÄtveÅ™ice bodÅ¯) je potÅ™ebnÃ½ pro perspektivnÃ­ transformaci v nÃ¡sledujÃ­cÃ­ fÃ¡zi. Detekce vyuÅ¾Ã­vÃ¡ hybrid pÅ™Ã­stup kterÃ½ kombinuje vÃ½hody rychlÃ© cache s robustnostÃ­ YOLO inference.

**Workflow detekce:**

PrvnÃ­ krok je pokus o naÄtenÃ­ quad z databÃ¡zovÃ© cache (tabulka `inference_frames`). Pokud byl tento konkrÃ©tnÃ­ sken uÅ¾ nÄ›kdy v minulosti zpracovÃ¡n, mÃ¡me uloÅ¾enÃ½ detekovanÃ½ quad a mÅ¯Å¾eme ho okamÅ¾itÄ› pouÅ¾Ã­t. NaÄtenÃ­ z cache je extrÃ©mnÄ› rychlÃ© (Å™Ã¡dovÄ› 1-2 milisekundy) protoÅ¾e jde pouze o SELECT query z SQLite databÃ¡ze.

Pokud quad v cache nenÃ­ (cache miss), spustÃ­ se YOLO inference. YOLO model je natrÃ©novanÃ½ na detekci rÃ¡meÄkÅ¯ ÄeskoslovenskÃ½ch znÃ¡mek a vracÃ­ oriented bounding box (OBB) - tedy ÄtyÅ™i rohovÃ© body mÃ­sto klasickÃ©ho axis-aligned obdÃ©lnÃ­ku. YOLO inference je podstatnÄ› pomalejÅ¡Ã­ neÅ¾ cache lookup (Å™Ã¡dovÄ› 300-500 milisekund na CPU), ale stÃ¡le dostateÄnÄ› rychlÃ¡ pro interaktivnÃ­ pouÅ¾itÃ­.

Pokud YOLO detekce uspÄ›je (confidence score je nad threshold, typicky 0.95), vÃ½slednÃ½ quad se uloÅ¾Ã­ do databÃ¡zovÃ© cache pro pÅ™Ã­Å¡tÃ­ pouÅ¾itÃ­. Toto uloÅ¾enÃ­ probÃ­hÃ¡ asynchronnÄ› - pokud selÅ¾e (napÅ™Ã­klad kvÅ¯li chybÄ› databÃ¡ze), YOLO vÃ½sledek je stÃ¡le platnÃ½ a pipeline pokraÄuje normÃ¡lnÄ›. CachovÃ¡nÃ­ je optimalizace, ne poÅ¾adavek pro sprÃ¡vnou funkci.

**ProÄ hybrid pÅ™Ã­stup:**
OpakovanÃ© zpracovÃ¡nÃ­ stejnÃ½ch skenÅ¯ je bÄ›Å¾nÃ½ scÃ©nÃ¡Å™ pÅ™i vÃ½voji a testovÃ¡nÃ­ systÃ©mu. NapÅ™Ã­klad pÅ™i ladÄ›nÃ­ threshold parametrÅ¯ nebo testovÃ¡nÃ­ novÃ© verze embedding modelu musÃ­me zpracovat celÃ½ testovacÃ­ dataset (6800 skenÅ¯). Bez cache by kaÅ¾dÃ½ bÄ›h trval pÅ™es hodinu pouze na YOLO detekci. S cache je druhÃ½ a dalÅ¡Ã­ bÄ›h stokrÃ¡t rychlejÅ¡Ã­ protoÅ¾e quad je uÅ¾ uloÅ¾enÃ½.

**TechnickÃ© detaily:**
```python
# Pokus o naÄtenÃ­ z cache
frame_row = get_cached_frame_by_path(conn, input_path)

if frame_row is not None:
    # Cache hit - pouÅ¾ij uloÅ¾enÃ½ quad
    quad = parse_quad_from_frame_row(frame_row)
    source = 'cache'
else:
    # Cache miss - spusÅ¥ YOLO inference
    quad, conf, bbox = detect_frame_yolo(
        image_path=input_path,
        model_path=yolo_model_path,
        conf_threshold=0.95
    )
    
    # Pokud YOLO ÃºspÄ›Å¡nÃ©, cachuj vÃ½sledek
    if quad is not None:
        upsert_inference_frame(conn, input_path, quad, conf, bbox)
        source = 'yolo'
```

**FormÃ¡t quad:**
Quad je numpy array tvaru (4, 2) obsahujÃ­cÃ­ souÅ™adnice ÄtyÅ™ rohovÃ½ch bodÅ¯ v poÅ™adÃ­: Top-Left, Top-Right, Bottom-Right, Bottom-Left. SouÅ™adnice jsou v pixelech pÅ¯vodnÃ­ho obrÃ¡zku (napÅ™. 2400Ã—3000). Toto poÅ™adÃ­ je kritickÃ© pro korektnÃ­ warp v dalÅ¡Ã­ fÃ¡zi.

### FÃ¡ze 4: Warp a normalizace na 1300Ã—1100

ÄŒtvrtÃ¡ fÃ¡ze provÃ¡dÃ­ perspektivnÃ­ transformaci (warp) znÃ¡mky do standardizovanÃ©ho formÃ¡tu 1300Ã—1100 pixelÅ¯. Vstupem je pÅ¯vodnÃ­ sken v libovolnÃ©m rozliÅ¡enÃ­ a quad detekovanÃ½ v pÅ™edchozÃ­ fÃ¡zi. VÃ½stupem je frontÃ¡lnÄ› narovnanÃ¡ znÃ¡mka v jednotnÃ©m rozliÅ¡enÃ­, pÅ™ipravenÃ¡ pro extrakci vÃ½Å™ezÅ¯.

**ÃšÄel warp transformace:**
UÅ¾ivatelskÃ© skeny jsou rÅ¯znÄ› natoÄenÃ©, vyfocenÃ© z Ãºhlu, nebo majÃ­ rÅ¯znÃ© rozliÅ¡enÃ­. NÄ›kterÃ© skeny jsou 2400Ã—3000 pixelÅ¯ z profesionÃ¡lnÃ­ho skeneru, jinÃ© 1920Ã—1080 z mobilnÃ­ho telefonu. ZnÃ¡mka mÅ¯Å¾e bÃ½t na skeneru poloÅ¾enÃ¡ Å¡ikmo nebo mÃ­rnÄ› zkosenÃ¡. Warp transformace vÅ¡echny tyto variace normalizuje do jednotnÃ©ho formÃ¡tu kde znÃ¡mka je vÅ¾dy frontÃ¡lnÄ› narovnanÃ¡, mÃ¡ stejnÃ© rozliÅ¡enÃ­ a stejnÃ© proporce.

Tato normalizace je kritickÃ¡ pro nÃ¡sledujÃ­cÃ­ fÃ¡ze. Definice vÃ½Å™ezÅ¯ (crops) v databÃ¡zi jsou uloÅ¾enÃ© jako relativnÃ­ souÅ™adnice na normalizovanÃ© znÃ¡mce 1300Ã—1100. NapÅ™Ã­klad "hodnotovÃ½ Å¡tÃ­tek" je definovanÃ½ jako elipsa na pozici (50%, 86%) se specifickÃ½m polomÄ›rem. Tyto relativnÃ­ souÅ™adnice funujÃ­ pouze kdyÅ¾ je znÃ¡mka ve standardizovanÃ©m formÃ¡tu.

**Jak warp funguje:**
Z quad (ÄtyÅ™i rohovÃ© body) a cÃ­lovÃ©ho rozmÄ›ru 1300Ã—1100 se vypoÄÃ­tÃ¡ homografickÃ¡ matice 3Ã—3 kterÃ¡ definuje perspektivnÃ­ transformaci. Tato matice se aplikuje na pÅ¯vodnÃ­ obrÃ¡zek pomocÃ­ OpenCV funkce `cv2.warpPerspective()`. VÃ½sledkem je obdÃ©lnÃ­kovÃ½ obrÃ¡zek 1300Ã—1100 kde znÃ¡mka je narovnanÃ¡ a mÃ¡ standardizovanÃ© proporce.

RozmÄ›r 1300Ã—1100 byl zvolen empiricky jako kompromis mezi kvalitou detailÅ¯ a vÃ½poÄetnÃ­ nÃ¡roÄnostÃ­. Je dostateÄnÄ› velkÃ½ aby zachoval jemnÃ© detaily jako spirÃ¡ly nebo ÄÃ­slovky na hodnotovÃ©m Å¡tÃ­tku, ale zÃ¡roveÅˆ dostateÄnÄ› malÃ½ aby vÃ½poÄet embeddingÅ¯ byl rychlÃ½. Proporce 1300:1100 pÅ™ibliÅ¾nÄ› odpovÃ­dajÃ­ reÃ¡lnÃ½m proporcÃ­m ÄeskoslovenskÃ½ch znÃ¡mek sÃ©rie HradÄany.

**Fallback pÅ™i selhÃ¡nÃ­ detekce:**
Pokud quad nebyl v pÅ™edchozÃ­ fÃ¡zi detekovÃ¡n (YOLO selhalo), pouÅ¾ije se fallback - prostÃ½ resize pÅ¯vodnÃ­ho obrÃ¡zku na 1300Ã—1100. To nenÃ­ ideÃ¡lnÃ­ protoÅ¾e znÃ¡mka mÅ¯Å¾e bÃ½t zkosenÃ¡ nebo mÃ­t Å¡patnÃ© proporce, ale umoÅ¾Åˆuje to pokraÄovat v pipeline alespoÅˆ s pÅ™ibliÅ¾nÃ½m vÃ½sledkem. V praxi YOLO detekce selhÃ¡vÃ¡ velmi vzÃ¡cnÄ› (< 0.1% pÅ™Ã­padÅ¯) takÅ¾e fallback je emergency Å™eÅ¡enÃ­. (MB ToDo: ukonÄit pipeline, pokud nenÃ­ YOLO detekce ÃºspÄ›Å¡nÃ¡)

**TechnickÃ© detaily:**
```python
# NaÄtenÃ­ pÅ¯vodnÃ­ho obrÃ¡zku
orig_bgr = cv2.imread(input_path)

if quad is not None:
    # Warp pomocÃ­ homografie
    H = compute_homography_matrix(quad, target_size=(1300, 1100))
    full_norm = cv2.warpPerspective(orig_bgr, H, (1300, 1100))
else:
    # Fallback - prostÃ½ resize
    full_norm = cv2.resize(orig_bgr, (1300, 1100), interpolation=cv2.INTER_AREA)
```

**VÃ½stup:**
PromÄ›nnÃ¡ `full_norm` obsahuje normalizovanou znÃ¡mku jako numpy array tvaru (1100, 1300, 3) v BGR color space. Tento obrÃ¡zek je pouÅ¾it ve vÅ¡ech nÃ¡sledujÃ­cÃ­ch fÃ¡zÃ­ch pro extrakci vÃ½Å™ezÅ¯.

### FÃ¡ze 5: Auto-detect denomination (pokud typ nenÃ­ zadÃ¡n)

PÃ¡tÃ¡ fÃ¡ze automaticky detekuje typ znÃ¡mky (denomination) pokud ho uÅ¾ivatel nezadal pomocÃ­ parametru `--denomination`. Detekce pouÅ¾Ã­vÃ¡ multi-phase algoritmus kterÃ½ kombinuje embedding similarity, OCR a HSV color matching pro robustnÃ­ klasifikaci.

**Kdy se fÃ¡ze spouÅ¡tÃ­:**
Pokud uÅ¾ivatel zadal `--denomination` parametr (napÅ™. `--denomination 500h`), tato fÃ¡ze se pÅ™eskakuje a pouÅ¾ije se zadanÃ½ typ. To je backward compatibility reÅ¾im kterÃ½ umoÅ¾Åˆuje manuÃ¡lnÃ­ zadÃ¡nÃ­ typu kdyÅ¾ vÃ­me co hledÃ¡me. Pokud parametr nenÃ­ zadÃ¡n, spustÃ­ se auto-detect workflow.

**Multi-phase detekce:**

PrvnÃ­ fÃ¡ze je embedding-based detection. SystÃ©m vyÅ™Ã­zne hodnotovÃ½ Å¡tÃ­tek z normalizovanÃ© znÃ¡mky (oblast kde je vytiÅ¡tÄ›nÃ¡ hodnota - napÅ™. "500"), vypoÄÃ­tÃ¡ embedding tohoto vÃ½Å™ezu a porovnÃ¡ ho s embeddingy hodnotovÃ½ch Å¡tÃ­tkÅ¯ vÅ¡ech 26 typÅ¯ znÃ¡mek v databÃ¡zi. Typicky se TOP-3 kandidÃ¡ti liÅ¡Ã­ jen o desetiny procenta v similarity, takÅ¾e pouze embedding nenÃ­ dostateÄnÃ½ pro jednoznaÄnÃ© urÄenÃ­.

DruhÃ¡ fÃ¡ze je OCR detekce (disambiguation). Pro TOP-K kandidÃ¡tÅ¯ z embedding fÃ¡ze (typicky K=10) se spustÃ­ OCR na hodnotovÃ©m Å¡tÃ­tku. OCR model (EasyOCR) extrahuje text ze Å¡tÃ­tku a pokusÃ­ se ho rozeznat jako ÄÃ­slo. Pokud OCR pÅ™eÄte napÅ™Ã­klad "500", mÅ¯Å¾eme s vysokou jistotou Å™Ã­ct Å¾e jde o 500h znÃ¡mku i kdyÅ¾ embedding similarity byla podobnÃ¡ jako u 50h15 nebo 50h16.

TÅ™etÃ­ fÃ¡ze je porovnÃ¡nÃ­ barev (HSV color verification). NÄ›kterÃ© typy znÃ¡mek existujÃ­ v rÅ¯znÃ½ch barevnÃ½ch variantÃ¡ch (napÅ™. 50h15 modrÃ¡ vs 50h16 zelenÃ¡) kterÃ© majÃ­ velmi podobnÃ© embeddings ale liÅ¡Ã­ se barvou. Pro finÃ¡lnÃ­ disambiguaci se porovnÃ¡ prÅ¯mÄ›rnÃ¡ barva znÃ¡mky v HSV color space s definovanÃ½mi HSV pravidly pro kaÅ¾dÃ½ typ. Pokud barva nesedÃ­, sniÅ¾uje se confidence nebo se kandidÃ¡t zamÃ­tne.

**VÃ½stup:**
Auto-detect vracÃ­ slovnÃ­k s klÃ­Äi: `denomination` (napÅ™. "500h"), `stamp_type_id` (ID v databÃ¡zi), `confidence_level` (HIGH/MEDIUM/LOW/MANUAL_REVIEW), `similarity` (embedding score), `ocr_text` (rozpoznanÃ½ text), `hsv_match` (boolean). Pokud je confidence LOW nebo MANUAL_REVIEW, pipeline se zastavÃ­ s chybovou hlÃ¡Å¡kou protoÅ¾e nemÅ¯Å¾eme pokraÄovat s nejistou klasifikacÃ­.

**ProÄ multi-phase:**
Embedding alone dÃ¡vÃ¡ dobrÃ© vÃ½sledky pro vÄ›tÅ¡inu pÅ™Ã­padÅ¯ ale selhÃ¡vÃ¡ u velmi podobnÃ½ch typÅ¯ (10h5 vs 15h, 50h15 vs 50h16). OCR alone selhÃ¡vÃ¡ u poÅ¡kozenÃ½ch nebo Å¡patnÄ› vytiÅ¡tÄ›nÃ½ch Å¡tÃ­tkÅ¯ (napÅ™. 1000h Äasto Äte jako "100"). Kombinace vÅ¡ech tÅ™Ã­ metod dosahuje 96.9% pÅ™esnosti na testovacÃ­m datasetu 6800 skenÅ¯.

**TechnickÃ© detaily:**
```python
from common.denomination_utils import auto_detect_denomination

result = auto_detect_denomination(
    conn=conn,
    warped_bgr=full_norm,
    encoder=encoder,
    topk=10,
    embedding_threshold=0.85,
    debug=False
)

if result['confidence_level'] in ['LOW', 'MANUAL_REVIEW']:
    raise ValueError(f"NÃ­zkÃ¡ confidence: {result['confidence_level']}")

denomination = result['denomination']  # napÅ™. "500h"
stamp_type_id = result['stamp_type_id']  # napÅ™. 5
```

### FÃ¡ze 6: NaÄtenÃ­ definic vÃ½Å™ezÅ¯ pro danou kresbu

Å estÃ¡ fÃ¡ze naÄÃ­tÃ¡ z databÃ¡ze definice vÃ½Å™ezÅ¯ (crops) pro konkrÃ©tnÃ­ kresbu znÃ¡mky. ÄŒeskoslovenskÃ© znÃ¡mky sÃ©rie HradÄany existujÃ­ v Å¡esti rÅ¯znÃ½ch kresbÃ¡ch (s popisem, s krouÅ¾ky, abstraktnÃ­, atd.) a kaÅ¾dÃ¡ kresba mÃ¡ svoje specifickÃ© vÃ½Å™ezy kterÃ© obsahujÃ­ charakteristickÃ© rysy potÅ™ebnÃ© pro identifikaci.

**Co je crop:**
Crop je definovanÃ¡ oblast na normalizovanÃ© znÃ¡mce 1300Ã—1100 kterÃ¡ obsahuje nÄ›jakÃ½ charakteristickÃ½ rys - napÅ™Ã­klad spirÃ¡la vlevo, obloha vpravo nahoÅ™e, keÅ™ s vÄ›tvemi, nebo hodnotovÃ½ Å¡tÃ­tek. KaÅ¾dÃ½ crop mÃ¡ pÅ™esnÄ› definovanÃ½ tvar (obdÃ©lnÃ­k, kruh, elipsa nebo polygon), pozici (relativnÃ­ souÅ™adnice od 0.0 do 1.0), padding (okraj navÃ­c kolem definovanÃ© oblasti) a polaritu (tmavÃ© na svÄ›tlÃ©m nebo svÄ›tlÃ© na tmavÃ©m).

Tyto definice jsou uloÅ¾enÃ© v databÃ¡zovÃ© tabulce `drawing_crops` a jsou pevnÄ› spojenÃ© s konkrÃ©tnÃ­ kresbou. NapÅ™Ã­klad kresba "s popisem" mÃ¡ crop na pozici nÃ¡pisu POÅ TA, zatÃ­mco kresba "s krouÅ¾ky" mÃ¡ crop na pozici hornÃ­ch krouÅ¾kÅ¯. Crops jsou navrÅ¾enÃ© expertnÄ› aby obsahovaly oblasti kterÃ© se liÅ¡Ã­ mezi rÅ¯znÃ½mi tiskovÃ½mi deskami nebo znÃ¡mkovÃ½mi poli.

**ProÄ multiple crops:**
PorovnÃ¡vÃ¡nÃ­ celÃ© znÃ¡mky jako jedinÃ©ho embeddings nenÃ­ dostateÄnÃ© pro jemnÃ© rozliÅ¡enÃ­ mezi deskami a pozicemi. RÅ¯znÃ© ÄÃ¡sti znÃ¡mky obsahujÃ­ rÅ¯znÃ© typy informacÃ­ - spirÃ¡la rozliÅ¡uje znÃ¡mkovÃ© pole v rÃ¡mci desky, obloha mÃ¡ texturu specifickou pro pole, keÅ™ s vÄ›tvemi rozliÅ¡uje desku. PorovnÃ¡vÃ¡nÃ­m kaÅ¾dÃ©ho cropu samostatnÄ› dostÃ¡vÃ¡me vector of similarities mÃ­sto single scalar, coÅ¾ umoÅ¾Åˆuje jemnÄ›jÅ¡Ã­ matching.

V databÃ¡zi jsou pro kaÅ¾dÃ½ crop uloÅ¾enÃ© parametry jako `is_required` (tento crop MUSÃ bÃ½t pouÅ¾it pro matching) a `verified` (tento crop byl ovÄ›Å™en expertem). Pipeline naÄÃ­tÃ¡ pouze required verified crops - typicky 4-8 crops per drawing.

**TechnickÃ© detaily:**
```sql
-- NaÄtenÃ­ required crops pro kresbu ID=5 (500h)
SELECT id, code, name, crop_type, grid_rect_json, padding, polarity
FROM drawing_crops
WHERE drawing_id = 5 AND is_required = 1 AND verified = 1
ORDER BY id;
```

**VÃ½stup:**
Seznam CropDef objektÅ¯ obsahujÃ­cÃ­ch: `id` (unique crop ID), `code` (napÅ™. "spirala_levy"), `crop_type` (box/circle/ellipse/poly), `grid_rect_json` (relativnÃ­ souÅ™adnice), `padding` (napÅ™. 0.05), `polarity` (ink/paper). Tyto definice jsou pouÅ¾itÃ© v dalÅ¡Ã­ fÃ¡zi pro extrakci konkrÃ©tnÃ­ch oblastÃ­ z normalizovanÃ© znÃ¡mky.

### FÃ¡ze 7: Extrakce vÃ½Å™ezÅ¯ a vÃ½poÄet embeddingÅ¯

SedmÃ¡ fÃ¡ze je jÃ¡dro rozpoznÃ¡vacÃ­ho procesu. Pro kaÅ¾dÃ½ crop definovanÃ½ v pÅ™edchozÃ­ fÃ¡zi se z normalizovanÃ© znÃ¡mky vyÅ™Ã­zne konkrÃ©tnÃ­ oblast, tato oblast se preprocessing upravÃ­ do formÃ¡tu oÄekÃ¡vanÃ©ho embedding modelem a vypoÄÃ­tÃ¡ se 512-dimenzionÃ¡lnÃ­ embedding vektor. VÃ½sledkem jsou query embeddings kterÃ© reprezentujÃ­ charakteristickÃ© rysy analyzovanÃ© znÃ¡mky.

**Extrakce cropu:**
KaÅ¾dÃ½ crop mÃ¡ definovanÃ½ tvar (box/circle/ellipse/poly) a relativnÃ­ souÅ™adnice na normalizovanÃ© znÃ¡mce 1300Ã—1100. Tyto relativnÃ­ souÅ™adnice se pÅ™evedou na pixelovÃ© souÅ™adnice a z `full_norm` obrÃ¡zku se vyÅ™Ã­zne pÅ™Ã­sluÅ¡nÃ¡ oblast. Pro non-rectangular shapes (kruh, elipsa) se vytvoÅ™Ã­ maska kterÃ¡ nastavÃ­ pixely mimo tvar na Äernou.

NapÅ™Ã­klad crop "spirÃ¡la vlevo" je definovanÃ½ jako elipsa na pozici (cx=0.25, cy=0.30) s polomÄ›ry (rx=0.08, ry=0.10). Na normalizovanÃ© znÃ¡mce 1300Ã—1100 to odpovÃ­dÃ¡ stÅ™edu na (325, 330) pixelech s polomÄ›ry (104, 110) pixelÅ¯. Z tohoto regionu se vyÅ™Ã­zne obdÃ©lnÃ­k a pixely mimo elipsu se nastavÃ­ na nulu.

K vÃ½Å™ezu se pÅ™idÃ¡ padding (typicky 5% navÃ­c kolem definovanÃ© oblasti) aby se zachytily i okolnÃ­ pixely kterÃ© mohou obsahovat uÅ¾iteÄnou informaci. Polarity parameter (ink/paper) urÄuje jestli invertovat pixely - "ink" znamenÃ¡ tmavÃ© na svÄ›tlÃ©m (normÃ¡lnÃ­), "paper" znamenÃ¡ svÄ›tlÃ© na tmavÃ©m (invertovanÃ©).

**VÃ½poÄet embedding:**
KaÅ¾dÃ½ vyÅ™Ã­znutÃ½ crop se pÅ™edÃ¡ do RealEncoder kterÃ½ ho pÅ™evede na 512D vektor. RealEncoder internÄ› provÃ¡dÃ­:
1. BGR â†’ RGB konverzi (OpenCV pouÅ¾Ã­vÃ¡ BGR, PyTorch oÄekÃ¡vÃ¡ RGB)
2. Resize na 224Ã—224 (vstupnÃ­ rozmÄ›r ResNet50)
3. Normalizaci do rozsahu [0, 1] (dÄ›lenÃ­ 255.0)
4. Konverzi na PyTorch tensor
5. Forward pass ResNet50 â†’ 2048D features
6. Projekce 2048D â†’ 512D pÅ™es natrÃ©novanou hlavu
7. L2 normalizaci vÃ½slednÃ©ho vektoru (norma = 1.0)

L2 normalizace je kritickÃ¡ protoÅ¾e umoÅ¾Åˆuje pouÅ¾Ã­t dot product mÃ­sto cosine similarity v dalÅ¡Ã­ fÃ¡zi. Pro dva L2-normalizovanÃ© vektory platÃ­: cosine_similarity(a, b) = dot(a, b). Dot product je vÃ½raznÄ› rychlejÅ¡Ã­ neÅ¾ vÃ½poÄet cosine similarity.

**TechnickÃ© detaily:**
```python
query_embeddings = []

for crop_def in required_crops:
    # 1. Extrahuj crop z full_norm podle definice
    crop_img = extract_crop_region(
        full_norm, 
        crop_def.crop_type,
        crop_def.grid_rect_json,
        crop_def.padding,
        crop_def.polarity
    )
    
    # 2. VypoÄÃ­taj embedding
    with torch.no_grad():
        emb = encoder(crop_img)  # (512,) L2-normalized
    
    query_embeddings.append({
        'crop_id': crop_def.id,
        'crop_code': crop_def.code,
        'embedding': emb.cpu().numpy()
    })
```

**VÃ½stup:**
Seznam slovnÃ­kÅ¯ kde kaÅ¾dÃ½ obsahuje `crop_id`, `crop_code` a `embedding` (numpy array shape (512,), dtype float32, L2-normalized). PoÄet embeddingÅ¯ odpovÃ­dÃ¡ poÄtu required crops (typicky 4-8).

### FÃ¡ze 8: Matching s referenÄnÃ­mi embeddingy

OsmÃ¡ fÃ¡ze porovnÃ¡vÃ¡ query embeddings vypoÄÃ­tanÃ© v pÅ™edchozÃ­ fÃ¡zi s referenÄnÃ­mi embeddingy uloÅ¾enÃ½mi v databÃ¡zi. Pro kaÅ¾dÃ½ query embedding najdeme TOP-K nejpodobnÄ›jÅ¡Ã­ch referenÄnÃ­ch embeddingÅ¯ pomocÃ­ cosine similarity. VÃ½sledkem je seznam match candidates s jejich similarity scores.

**ReferenÄnÃ­ embeddings v databÃ¡zi:**
DatabÃ¡zovÃ¡ tabulka `reference_embeddings` obsahuje embeddings vypoÄÃ­tanÃ© ze vÅ¡ech znÃ¡mÃ½ch referenÄnÃ­ch skenÅ¯. Pro kaÅ¾dÃ½ referenÄnÃ­ sken (napÅ™Ã­klad 500h TD1 ZP42) existuje nÄ›kolik embeddingÅ¯ - jeden pro kaÅ¾dÃ½ required crop. Celkem databÃ¡ze obsahuje pÅ™ibliÅ¾nÄ› 50,000 embeddingÅ¯ (6800 skenÅ¯ Ã— prÅ¯mÄ›rnÄ› 7 crops per sken).

KaÅ¾dÃ½ embedding je uloÅ¾enÃ½ jako BLOB (binary large object) - serializovanÃ½ numpy array float32[512] kterÃ½ zabÃ­rÃ¡ 2048 bytÅ¯. K embeddings jsou navÃ¡zanÃ© metadata: `scan_id` (odkaz na referenÄnÃ­ sken), `crop_id` (kterÃ½ crop to je), `model_id` (kterÃ½m modelem byl vypoÄÃ­tanÃ½), `l2_norm` (norma vektoru, vÅ¾dy 1.0).

**Matching algoritmus:**
Pro kaÅ¾dÃ½ query embedding se provede SQL query kterÃ¡ najde TOP-K nejpodobnÄ›jÅ¡Ã­ch referenÄnÃ­ch embeddingÅ¯ se STEJNÃM crop_id. ProÄ stejnÃ½ crop_id? ProtoÅ¾e embeddings rÅ¯znÃ½ch crops nejsou porovnatelnÃ© - spirÃ¡la mÃ¡ jinÃ½ vÃ½znam neÅ¾ obloha, jejich embeddings leÅ¾Ã­ v jinÃ½ch regionech 512D prostoru. PorovnÃ¡vÃ¡me vÅ¾dy pouze "spirÃ¡la query" vs "spirÃ¡ly reference".

Podobnost se poÄÃ­tÃ¡ jako dot product (skalÃ¡rnÃ­ souÄin) dvou L2-normalizovanÃ½ch vektorÅ¯. Pro vektory s normou 1.0 platÃ­: dot(a, b) = cosine(angle(a, b)). ÄŒÃ­m vÄ›tÅ¡Ã­ dot product, tÃ­m menÅ¡Ã­ Ãºhel mezi vektory, tÃ­m podobnÄ›jÅ¡Ã­ jsou embeddings. Hodnoty jsou v rozsahu [-1, 1] kde 1 = identickÃ©, 0 = ortogonÃ¡lnÃ­, -1 = opaÄnÃ©.

Matching se provÃ¡dÃ­ pouze v rÃ¡mci stejnÃ© kresby (drawing_id). Nelze porovnÃ¡vat znÃ¡mku s kresbou "s popisem" proti znÃ¡mce s kresbou "abstraktnÃ­" protoÅ¾e majÃ­ jinÃ© crops a embeddings nejsou kompatibilnÃ­.

**TechnickÃ© detaily:**
```sql
-- Pro kaÅ¾dÃ½ query embedding (napÅ™. spirala_levy, crop_id=8)
-- najdi TOP-10 nejpodobnÄ›jÅ¡Ã­ch referenÄnÃ­ch embeddingÅ¯

WITH query AS (
    SELECT ? AS query_embedding  -- binding: serialized numpy array
)
SELECT 
    re.scan_id,
    rf.plate_id,
    rf.zp_no,
    dot_product(re.vec, query.query_embedding) AS similarity
FROM reference_embeddings re
JOIN reference_front rf ON re.scan_id = rf.id
CROSS JOIN query
WHERE 
    re.crop_id = 8                    -- STEJNÃ crop jako query
    AND rf.drawing_id = 5             -- STEJNÃ kresba
    AND rf.confirmed = 1              -- pouze potvrzenÃ© reference
ORDER BY similarity DESC
LIMIT 10;
```

**VÃ½stup:**
Pro kaÅ¾dÃ½ query embedding dostaneme seznam TOP-K matches obsahujÃ­cÃ­: `scan_id` (referenÄnÃ­ sken), `plate_id` (tiskovÃ¡ deska), `zp_no` (znÃ¡mkovÃ© pole), `similarity` (cosine similarity score 0.0-1.0). Celkem tedy mÃ¡me N_crops Ã— K matches (napÅ™. 5 crops Ã— 10 matches = 50 match records).

### FÃ¡ze 9: Agregace a ranking kandidÃ¡tÅ¯

DevÃ¡tÃ¡ fÃ¡ze agreguje match results z pÅ™edchozÃ­ fÃ¡ze do kandidÃ¡tÅ¯ definovanÃ½ch kombinacÃ­ (tiskovÃ¡ deska, znÃ¡mkovÃ© pole) a seÅ™adÃ­ je podle prÅ¯mÄ›rnÃ© podobnosti. VÃ½sledkem je ranked list TOP-K kandidÃ¡tÅ¯ kde kaÅ¾dÃ½ kandidÃ¡t mÃ¡ agregovanÃ© statistiky podobnosti across all crops.

**Co je kandidÃ¡t:**
KandidÃ¡t je kombinace (plate_id, zp_no) - napÅ™Ã­klad TD1 ZP42. Pro kaÅ¾dÃ©ho kandidÃ¡ta mÃ¡me nÄ›kolik similarity scores - jeden pro kaÅ¾dÃ½ crop kterÃ½ byl matchovÃ¡n. NapÅ™Ã­klad pro kandidÃ¡ta TD1 ZP42 mÅ¯Å¾eme mÃ­t: spirala_levy=0.89, obloha=0.87, ker_vetve=0.91, hodnotovy_stitek=0.93.

**Agregace:**
Pro kaÅ¾dÃ©ho kandidÃ¡ta vypoÄÃ­tÃ¡me agregaÄnÃ­ statistiky ze vÅ¡ech similarity scores:
- **mean** (prÅ¯mÄ›r): hlavnÃ­ metrika pro ranking, reprezentuje celkovou podobnost
- **median** (mediÃ¡n): robustnÄ›jÅ¡Ã­ vÅ¯Äi outliers neÅ¾ mean
- **min** (minimum): ukazuje nejhorÅ¡Ã­ match, uÅ¾iteÄnÃ© pro detekci false positives
- **max** (maximum): ukazuje nejlepÅ¡Ã­ match
- **std** (smÄ›rodatnÃ¡ odchylka): ukazuje variabilitu matchÅ¯
- **n** (count): poÄet cropÅ¯ kterÃ© byly matchovanÃ©

PrÅ¯mÄ›rnÃ¡ podobnost (mean) je pouÅ¾itÃ¡ jako primÃ¡rnÃ­ ranking metrika. KandidÃ¡ti jsou seÅ™azenÃ­ sestupnÄ› podle mean similarity - ÄÃ­m vyÅ¡Å¡Ã­ prÅ¯mÄ›r, tÃ­m podobnÄ›jÅ¡Ã­ kandidÃ¡t.

**ProÄ agregace:**
Single crop match mÅ¯Å¾e bÃ½t zavÃ¡dÄ›jÃ­cÃ­ - napÅ™Ã­klad spirÃ¡la mÅ¯Å¾e bÃ½t podobnÃ¡ nÃ¡hodou i kdyÅ¾ zbytek znÃ¡mky je ÃºplnÄ› jinÃ½. AgregacÃ­ across multiple crops dostÃ¡vÃ¡me robustnÄ›jÅ¡Ã­ klasifikaci. Pokud mÃ¡ kandidÃ¡t konzistentnÄ› vysokou podobnost na vÅ¡ech crops (mean=0.92, median=0.91, min=0.89, max=0.94), je to silnÃ½ signÃ¡l Å¾e jde o sprÃ¡vnÃ½ match. Naopak velkÃ¡ variance (min=0.75, max=0.95) naznaÄuje nejistÃ½ match.

**Best scan selection:**
Pro kaÅ¾dÃ©ho kandidÃ¡ta (TD, ZP kombinaci) mÅ¯Å¾e existovat nÄ›kolik referenÄnÃ­ch skenÅ¯ v databÃ¡zi (rÅ¯znÃ© exemplÃ¡Å™e stejnÃ© znÃ¡mky). VybÃ­rÃ¡ se "best scan" - ten se nejvyÅ¡Å¡Ã­ prÅ¯mÄ›rnou similarity. Tento scan se pouÅ¾ije pro vizualizaci v pÅ™Ã­padÄ› Å¾e uÅ¾ivatel poÅ¾aduje compare-full mozaiku.

**TechnickÃ© detaily:**
```python
from collections import defaultdict
import numpy as np

# Agregace matchÅ¯ po kandidÃ¡tech
candidates = defaultdict(list)

for match in all_matches:
    key = (match['plate_id'], match['zp_no'])
    candidates[key].append(match['similarity'])

# VÃ½poÄet statistik pro kaÅ¾dÃ©ho kandidÃ¡ta
ranked_candidates = []

for (plate_id, zp_no), similarities in candidates.items():
    sim_array = np.array(similarities)
    
    candidate = {
        'plate_id': plate_id,
        'zp_no': zp_no,
        'mean': np.mean(sim_array),
        'median': np.median(sim_array),
        'min': np.min(sim_array),
        'max': np.max(sim_array),
        'std': np.std(sim_array),
        'n': len(sim_array)
    }
    
    ranked_candidates.append(candidate)

# SeÅ™azenÃ­ sestupnÄ› podle mean similarity
ranked_candidates.sort(key=lambda c: c['mean'], reverse=True)

# TOP-K vÃ½bÄ›r (typicky K=10)
top_candidates = ranked_candidates[:args.topk]
```

**VÃ½stup:**
Seznam TOP-K kandidÃ¡tÅ¯ (defaultnÄ› K=10) seÅ™azenÃ½ch podle prÅ¯mÄ›rnÃ© podobnosti. KaÅ¾dÃ½ kandidÃ¡t obsahuje: `plate_id`, `zp_no`, `denomination`, `color_name`, agregaÄnÃ­ statistiky (`mean`, `median`, `min`, `max`, `std`, `n`), `best_scan_id` (pro vizualizaci). TÃ­mto konÄÃ­ core recognition workflow - fÃ¡ze 1-9.

### FÃ¡ze 10: DB UPSERT - VytvoÅ™enÃ­/aktualizace zÃ¡znamu (VOLITELNÃ‰)

âš ï¸ **POZNÃMKA:** Tato fÃ¡ze NENÃ souÄÃ¡stÃ­ zlatÃ©ho standardu pro recognition. SlouÅ¾Ã­ pro specifickÃ© potÅ™eby programu `recognize_stamp.py` v UC-2 workflow (verify pending scans).

DesÃ¡tÃ¡ fÃ¡ze vytvoÅ™Ã­ nebo aktualizuje zÃ¡znam analyzovanÃ©ho skenu v databÃ¡zovÃ© tabulce `reference_front`. Pokud sken uÅ¾ v databÃ¡zi existuje (identifikovanÃ½ pomocÃ­ `file_path`), aktualizujÃ­ se jeho metadata (SHA256 hash, rozliÅ¡enÃ­, uploaded_by). Pokud sken neexistuje, vytvoÅ™Ã­ se novÃ½ pending zÃ¡znam s `confirmed=0`.

**ÃšÄel:**
Program `recognize_stamp.py` mÅ¯Å¾e bÃ½t pouÅ¾it jak pro rozpoznÃ¡vÃ¡nÃ­ novÃ½ch neznÃ¡mÃ½ch znÃ¡mek (bÄ›Å¾nÃ½ use case), tak pro analÃ½zu pending skenÅ¯ pÅ™ed jejich zaÅ™azenÃ­m do Ground Truth databÃ¡ze (UC-2 workflow). V druhÃ©m pÅ™Ã­padÄ› je potÅ™eba vytvoÅ™it databÃ¡zovÃ½ zÃ¡znam kterÃ½ expert pozdÄ›ji potvrdÃ­ pomocÃ­ `gt_file_manager.py --action verify`.

**Co se uklÃ¡dÃ¡:**
- `file_path`: relativnÃ­ cesta k pÅ¯vodnÃ­mu skenu (ne k warpu!)
- `file_sha256`: SHA256 hash PÅ®VODNÃHO skenu (ne warpu)
- `resolution_w`, `resolution_h`: rozmÄ›ry PÅ®VODNÃHO skenu
- `stamp_type_id`: typ znÃ¡mky z auto-detect (nebo NULL pokud manual input)
- `plate_id`, `zp_no`: 0 (pending - bude vyplnÄ›no pÅ™i verify)
- `confirmed`: 0 (pending expert verification)
- `uploaded_by`: username@hostname aktuÃ¡lnÃ­ho uÅ¾ivatele

**ProÄ nenÃ­ souÄÃ¡stÃ­ zlatÃ©ho standardu:**
GT Management mÃ¡ vlastnÃ­ upload workflow (UC-1) kterÃ½ sprÃ¡vnÄ› implementuje file storage s SHA256 naming a proper deduplication. `recognize_stamp.py` vznikl pÅ™ed GT Management a jeho DB UPSERT je legacy feature. NovÃ© implementace by mÄ›ly pouÅ¾Ã­t `gt_upload_utils.py` mÃ­sto tÃ©to fÃ¡ze.

**TechnickÃ© detaily:**
```python
# Zkontroluj jestli sken uÅ¾ existuje
existing = find_scan(conn, file_path=relative_path)

if existing:
    # UPDATE metadata
    update_scan_metadata(
        conn, existing['id'],
        file_sha256=compute_sha256(input_path),
        resolution_w=orig_bgr.shape[1],
        resolution_h=orig_bgr.shape[0],
        uploaded_by=f"{username}@{hostname}"
    )
else:
    # INSERT novÃ½ pending zÃ¡znam
    scan_id = insert_scan(
        conn,
        file_path=relative_path,
        stamp_type_id=stamp_type_id,
        plate_id=0,  # pending
        zp_no=0,     # pending
        confirmed=0,
        file_sha256=compute_sha256(input_path),
        resolution_w=orig_bgr.shape[1],
        resolution_h=orig_bgr.shape[0],
        uploaded_by=f"{username}@{hostname}"
    )
```

### FÃ¡ze 11: Auto-load notes - NaÄtenÃ­ poznÃ¡mek (VOLITELNÃ‰)

âš ï¸ **POZNÃMKA:** Tato fÃ¡ze NENÃ souÄÃ¡stÃ­ zlatÃ©ho standardu pro recognition. SlouÅ¾Ã­ pro specifickÃ© potÅ™eby programu `recognize_stamp.py` v UC-3 workflow (pending notes management).

JedenÃ¡ctÃ¡ fÃ¡ze naÄÃ­tÃ¡ poznÃ¡mky a metadata z .notes.json souboru pokud existuje vedle analyzovanÃ©ho skenu. Tyto poznÃ¡mky (napÅ™. "zakoupeno z aukce Burda, lot 123" nebo "poÅ¡kozenÃ½ levÃ½ okraj") se uloÅ¾Ã­ do databÃ¡zovÃ©ho zÃ¡znamu a .notes.json soubor se smaÅ¾e.

**ÃšÄel:**
PÅ™i pÅ™idÃ¡vÃ¡nÃ­ novÃ½ch skenÅ¯ do pending queue pomocÃ­ `gt_file_manager.py --action add --note "..."` se poznÃ¡mky uklÃ¡dajÃ­ do .notes.json souboru vedle skenu. PÅ™i prvnÃ­m spuÅ¡tÄ›nÃ­ `recognize_stamp.py` na takovÃ½ sken se tyto poznÃ¡mky pÅ™enesou do databÃ¡ze aby byly dostupnÃ© expertovi pÅ™i verify workflow.

**FormÃ¡t .notes.json:**
```json
{
  "note": "zakoupeno z aukce Burda 2025-11-28, lot 123",
  "source": "Burda",
  "added_at": "2025-11-28T14:32:00"
}
```

**Co se dÄ›je:**
Pokud `{input_path}.notes.json` existuje, naÄte se JSON obsah, extrahujÃ­ se klÃ­Äe `note` a `source` a uloÅ¾Ã­ se do databÃ¡zovÃ©ho zÃ¡znamu pomocÃ­ `update_scan_metadata(conn, scan_id, notes=note, source=source)`. Po ÃºspÄ›Å¡nÃ©m uloÅ¾enÃ­ se .notes.json soubor smaÅ¾e aby nedoÅ¡lo k duplikaci dat.

**ProÄ nenÃ­ souÄÃ¡stÃ­ zlatÃ©ho standardu:**
Toto je specifickÃ¡ feature pro workflow `gt_file_manager.py` + `recognize_stamp.py`. ObecnÃ½ recognition systÃ©m nemÃ¡ co dÄ›lat s notes management - poznÃ¡mky jsou business logic GT Management subsystÃ©mu.

### FÃ¡ze 12: Output - VÃ½pis TOP-K vÃ½sledkÅ¯

DvanÃ¡ctÃ¡ fÃ¡ze zobrazuje vÃ½sledky rozpoznÃ¡vÃ¡nÃ­ v uÅ¾ivatelsky ÄitelnÃ©m formÃ¡tu. VypÃ­Å¡e se TOP-K kandidÃ¡tÅ¯ (typicky K=10) seÅ™azenÃ½ch podle prÅ¯mÄ›rnÃ© podobnosti, vÄetnÄ› agregaÄnÃ­ch statistik pro kaÅ¾dÃ©ho kandidÃ¡ta. DÃ¡le se vypÃ­Å¡e SCAN INFO s metadaty analyzovanÃ©ho skenu pro ÃºÄely verify workflow.

**FormÃ¡t vÃ½pisu TOP-K kandidÃ¡tÅ¯:**
```
================================================================================
TOP-10 KANDIDÃTI (podle prÅ¯mÄ›rnÃ© podobnosti):
================================================================================
#1   500h ÄervenÃ¡                      TD  1  ZP  42  mean=0.9234  median=0.9189  min=0.8876  max=0.9456  n=5
#2   500h ÄervenÃ¡                      TD  1  ZP  43  mean=0.9187  median=0.9145  min=0.8823  max=0.9401  n=5
#3   500h ÄervenÃ¡                      TD  1  ZP  41  mean=0.9156  median=0.9112  min=0.8789  max=0.9378  n=5
...
```

**VÃ½klad metrik:**
- **mean**: prÅ¯mÄ›rnÃ¡ cosine similarity (hlavnÃ­ metrika pro ranking)
- **median**: mediÃ¡n similarity (robustnÄ›jÅ¡Ã­ vÅ¯Äi outliers)
- **min/max**: rozsah similarity (ukazuje variabilitu matchÅ¯)
- **n**: poÄet cropÅ¯ kterÃ© byly porovnanÃ©

**SCAN INFO vÃ½pis:**
```
================================================================================
SCAN INFO (pro verify):
================================================================================
scan_id:      6902
file_path:    data/pending/2025-11/scan_001.jpg
file_sha256:  2f9186b896fb...
resolution:   2400Ã—3000
uploaded_by:  milan@zenbook
notes:        zakoupeno z aukce Burda, lot 123
source:       Burda

Pro verify pouÅ¾ij:
  python tools/gt_file_manager.py --action verify \
      --scan-id 6902 \
      --plate 1 \
      --zp 42 \
      --env dev
```

**ÃšÄel SCAN INFO:**
KdyÅ¾ expert kontroluje vÃ½sledky recognition a vidÃ­ Å¾e TOP-1 kandidÃ¡t je sprÃ¡vnÃ½, potÅ™ebuje `scan_id` pro verify pÅ™Ã­kaz. SCAN INFO poskytuje vÅ¡echny potÅ™ebnÃ© Ãºdaje vÄetnÄ› ready-to-copy command line pro verify workflow.

### FÃ¡ze 13: Validation - Kontrola oÄekÃ¡vanÃ©ho vÃ½sledku (VOLITELNÃ‰)

TÅ™inÃ¡ctÃ¡ fÃ¡ze kontroluje jestli oÄekÃ¡vanÃ½ vÃ½sledek (pokud byl zadÃ¡n pomocÃ­ `--expect-plate` a `--expect-zp` parametrÅ¯) je v seznamu TOP-K kandidÃ¡tÅ¯ a na jakÃ© pozici. Tato fÃ¡ze se pouÅ¾Ã­vÃ¡ pouze pÅ™i testovÃ¡nÃ­ pÅ™esnosti systÃ©mu na znÃ¡mÃ½ch datech.

**ÃšÄel:**
PÅ™i batch testovÃ¡nÃ­ recognition accuracy mÃ¡me dataset kde znÃ¡me sprÃ¡vnou odpovÄ›Ä (ground truth). NapÅ™Ã­klad vÃ­me Å¾e `scan_500h_TD1_ZP042.jpg` obsahuje znÃ¡mku TD1 ZP42. SpustÃ­me recognition s `--expect-plate 1 --expect-zp 42` a systÃ©m vypÃ­Å¡e jestli sprÃ¡vnÃ¡ odpovÄ›Ä je na pozici #1, #2, ... nebo nenÃ­ v TOP-K vÅ¯bec.

**VÃ½stup:**
```
[INFO] OÄekÃ¡vanÃ½ kandidÃ¡t 500h ÄervenÃ¡ TD 1 ZP 42 je na pozici #1
```

nebo

```
[WARN] OÄekÃ¡vanÃ½ kandidÃ¡t 500h ÄervenÃ¡ TD 1 ZP 42 NENÃ v seznamu!
```

**PouÅ¾itÃ­:**
```bash
# Test accuracy na znÃ¡mÃ©m skenu
python recognize_stamp.py \
    --env dev \
    --input baseline/500h_TD1_ZP042.jpg \
    --denomination 500h \
    --expect-plate 1 \
    --expect-zp 42

# Batch test celÃ©ho datasetu
for scan in baseline/*.jpg; do
    # Parse expected TD and ZP from filename
    # Run recognition with --expect-plate and --expect-zp
    # Aggregate results: success if rank=#1, failure otherwise
done
```

### FÃ¡ze 14: Visualization - Mozaika porovnÃ¡nÃ­ (VOLITELNÃ‰)

ÄŒtrnÃ¡ctÃ¡ fÃ¡ze vytvoÅ™Ã­ vizuÃ¡lnÃ­ mozaiku kterÃ¡ vedle sebe zobrazuje analyzovanÃ½ sken a TOP-K nejpodobnÄ›jÅ¡Ã­ch referenÄnÃ­ch skenÅ¯. Mozaika se uloÅ¾Ã­ jako PNG soubor pro vizuÃ¡lnÃ­ kontrolu vÃ½sledkÅ¯.

**ÃšÄel:**
ÄŒÃ­sla similarity scores jsou abstraktnÃ­ - 0.9234 vs 0.9187 nenÃ­ intuitivnÃ­ rozdÃ­l. VizuÃ¡lnÃ­ mozaika umoÅ¾Åˆuje expertovi rychle vidÄ›t jestli TOP-K kandidÃ¡ti opravdu vypadajÃ­ podobnÄ› jako analyzovanÃ¡ znÃ¡mka. To je uÅ¾iteÄnÃ© pÅ™i ladÄ›nÃ­ systÃ©mu nebo pÅ™i kontrole edge cases.

**FormÃ¡t mozaiky:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   QUERY     â”‚   RANK #1   â”‚   RANK #2   â”‚
â”‚  (warped)   â”‚  (warped)   â”‚  (warped)   â”‚
â”‚             â”‚ TD1 ZP42    â”‚ TD1 ZP43    â”‚
â”‚             â”‚ mean=0.9234 â”‚ mean=0.9187 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  RANK #3    â”‚   RANK #4   â”‚   RANK #5   â”‚
â”‚  (warped)   â”‚  (warped)   â”‚  (warped)   â”‚
â”‚ TD1 ZP41    â”‚ TD1 ZP45    â”‚ TD2 ZP12    â”‚
â”‚ mean=0.9156 â”‚ mean=0.9134 â”‚ mean=0.9089 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**PouÅ¾itÃ­:**
```bash
python recognize_stamp.py \
    --env dev \
    --input scan.jpg \
    --denomination 500h \
    --topk 10 \
    --compare-full  # â† Aktivuje vizualizaci
```

**VÃ½stup:**
PNG soubor v `{env}/data/outputs/recognition/compare_{input_stem}_top{K}.png`. Mozaika mÃ¡ fixnÃ­ velikost panelÅ¯ (napÅ™. 300Ã—250 px per panel) a automaticky se layoutuje do grid.

---

## ğŸ”‘ KLÃÄŒOVÃ‰ KONCEPTY

### ProÄ pouÅ¾Ã­vÃ¡me multiple crops mÃ­sto celÃ© znÃ¡mky

RozpoznÃ¡vÃ¡nÃ­ znÃ¡mky jako celku (single embedding pro celou znÃ¡mku) by bylo jednoduÅ¡Å¡Ã­ implementaÄnÄ›, ale vÃ½raznÄ› mÃ©nÄ› pÅ™esnÃ©. DÅ¯vod je v tom Å¾e rÅ¯znÃ© ÄÃ¡sti znÃ¡mky obsahujÃ­ rÅ¯znÃ© typy informacÃ­ kterÃ© slouÅ¾Ã­ k rozliÅ¡enÃ­ na rÅ¯znÃ½ch ÃºrovnÃ­ch.

**HodnotovÃ½ Å¡tÃ­tek** obsahuje vytiÅ¡tÄ›nou hodnotu (napÅ™. "500") a slouÅ¾Ã­ primÃ¡rnÄ› k urÄenÃ­ typu znÃ¡mky (denomination). Je to nejdÅ¯leÅ¾itÄ›jÅ¡Ã­ crop pro auto-detect workflow protoÅ¾e kombinace embedding + OCR na Å¡tÃ­tku dosahuje velmi vysokÃ© pÅ™esnosti.

**SpirÃ¡ly** (levÃ¡ a pravÃ¡) jsou dekorativnÃ­ elementy kterÃ© se liÅ¡Ã­ mezi znÃ¡mkovÃ½mi poli v rÃ¡mci stejnÃ© tiskovÃ© desky. NapÅ™Ã­klad na TD1 mÃ¡ ZP42 spirÃ¡lu otevÅ™enou zatÃ­mco ZP43 mÃ¡ spirÃ¡lu zavÅ™enou. Embedding spirÃ¡ly tedy rozliÅ¡uje pÅ™edevÅ¡Ã­m pozici na desce.

**Obloha** (pravÃ¡ hornÃ­ oblast) mÃ¡ jemnou texturu kterÃ¡ je specifickÃ¡ pro kaÅ¾dÃ© znÃ¡mkovÃ© pole. Tato textura vznikÃ¡ kombinacÃ­ tlakovÃ© sÃ­ly pÅ™i tisku a mikroskopickÃ½ch nerovnostÃ­ na papÃ­ru. Je to jeden z nejsilnÄ›jÅ¡Ã­ch rysÅ¯ pro rozliÅ¡enÃ­ ZP pozic.

**KeÅ™ s vÄ›tvemi** (levÃ¡ dolnÃ­ oblast) rozliÅ¡uje pÅ™edevÅ¡Ã­m tiskovÃ© desky. RÅ¯znÃ© desky majÃ­ mÃ­rnÄ› odliÅ¡nÃ© pozice vÄ›tvÃ­ nebo jejich sÃ­lu, coÅ¾ se projevuje v embedding representaci.

**ÄŒÃ­slice a pÃ­smena** (pokud jsou na znÃ¡mce) slouÅ¾Ã­ k OCR verifikaci a disambiguation mezi podobnÃ½mi typy (10h5 vs 15h, 50h15 vs 50h16).

PorovnÃ¡vÃ¡nÃ­m kaÅ¾dÃ©ho cropu samostatnÄ› dostÃ¡vÃ¡me vektor podobnostÃ­ mÃ­sto single scalar. NapÅ™Ã­klad pro kandidÃ¡ta TD1 ZP42 mÅ¯Å¾eme mÃ­t: hodnotovy_stitek=0.95 (silnÃ½ match type), spirala_levy=0.89 (stÅ™ednÃ­ match pozice), obloha=0.93 (silnÃ½ match pozice), ker_vetve=0.91 (silnÃ½ match desky). AgregacÃ­ tÄ›chto podobnostÃ­ dostÃ¡vÃ¡me robustnÄ›jÅ¡Ã­ klasifikaci neÅ¾ single embedding.

### Embedding vs OCR vs HSV - proÄ vÅ¡echny tÅ™i metody

Recognition pipeline pouÅ¾Ã­vÃ¡ kombinaci tÅ™Ã­ rÅ¯znÃ½ch metod proto Å¾e kaÅ¾dÃ¡ mÃ¡ svÃ© silnÃ© a slabÃ© strÃ¡nky a dohromady se navzÃ¡jem doplÅˆujÃ­.

**Embedding similarity** je velmi robustnÃ­ vÅ¯Äi variabilitÄ› ve skenu - rÅ¯znÃ© osvÄ›tlenÃ­, mÃ­rnÃ© poÅ¡kozenÃ­, nebo neÄistoty na znÃ¡mce nemajÃ­ velkÃ½ vliv na embedding reprezentaci. ResNet50 je natrÃ©novanÃ½ na obrovskÃ©m datasetu a nauÄil se extrahovat high-level features kterÃ© jsou invariantnÃ­ vÅ¯Äi tÄ›mto distortions. Embedding similarity dosahuje excelentnÃ­ch vÃ½sledkÅ¯ na vÄ›tÅ¡inÄ› znÃ¡mek, ale mÃ¡ problÃ©m s velmi podobnÃ½mi typy kterÃ© se liÅ¡Ã­ pouze v ÄÃ­slici (10h5 vs 15h) nebo barvÄ› (50h15 modrÃ¡ vs 50h16 zelenÃ¡).

**OCR (Optical Character Recognition)** Äte text z hodnotovÃ©ho Å¡tÃ­tku a pÅ™evÃ¡dÃ­ ho na string kterÃ½ mÅ¯Å¾eme parsovat. Pro disambiguation mezi 10h5 a 15h staÄÃ­ pÅ™eÄÃ­st "10" vs "15". OCR je velmi pÅ™esnÃ© na kvalitnÃ­ch skenech ale selhÃ¡vÃ¡ na poÅ¡kozenÃ½ch nebo Å¡patnÄ› vytiÅ¡tÄ›nÃ½ch Å¡tÃ­tcÃ­ch. NapÅ™Ã­klad 1000h znÃ¡mky Äasto Äte jako "100" nebo "10O" protoÅ¾e nuly splÃ½vajÃ­. OCR alone by tedy nedosahoval dobrÃ© accuracy.

**HSV color matching** porovnÃ¡vÃ¡ prÅ¯mÄ›rnou barvu znÃ¡mky v HSV color space s definovanÃ½mi pravidly pro kaÅ¾dÃ½ typ. Pro disambiguation mezi 50h15 (modrÃ¡) a 50h16 (zelenÃ¡) staÄÃ­ zkontrolovat Hue channel. HSV matching je rychlÃ© a spolehlivÃ© pro barevnou variantu ale nedokÃ¡Å¾e rozliÅ¡it mezi typy se stejnou barvou.

Kombinace vÅ¡ech tÅ™Ã­ metod (multi-phase detection) dosahuje 96.9% success rate na testovacÃ­m datasetu 6800 skenÅ¯. Embedding poskytuje kandidÃ¡ty, OCR disambiguuje ÄÃ­slice, HSV verifikuje barvu. Å½Ã¡dnÃ¡ metoda alone by nedosÃ¡hla takovÃ© accuracy.

### DeterministickÃ© chovÃ¡nÃ­ - proÄ je to dÅ¯leÅ¾itÃ©

Pipeline je navrÅ¾enÃ¡ tak aby stejnÃ½ vstup vÅ¾dy produkoval stejnÃ½ vÃ½stup. To znamenÃ¡ Å¾e pokud spustÃ­me recognition na stejnÃ©m skenu dvakrÃ¡t (se stejnÃ½mi parametry), dostaneme naprosto identickÃ© vÃ½sledky - stejnÃ© TOP-K kandidÃ¡ty ve stejnÃ©m poÅ™adÃ­ se stejnÃ½mi similarity scores aÅ¾ na poslednÃ­ desetinnÃ© mÃ­sto.

DeterministickÃ© chovÃ¡nÃ­ je kritickÃ© ze tÅ™Ã­ dÅ¯vodÅ¯:

**Reprodukovatelnost testovÃ¡nÃ­:** KdyÅ¾ mÄ›Å™Ã­me pÅ™esnost systÃ©mu na testovacÃ­m datasetu, potÅ™ebujeme aby vÃ½sledky byly reprodukovatelnÃ©. Pokud bychom dnes namÄ›Å™ili 96.9% success rate a zÃ­tra 95.2% na stejnÃ©m datasetu (kvÅ¯li random variabilitÄ›), nevÄ›dÄ›li bychom jestli jsme systÃ©m zlepÅ¡ili nebo zhorÅ¡ili. DeterministickÃ© chovÃ¡nÃ­ umoÅ¾Åˆuje spolehlivÃ© A/B testovÃ¡nÃ­ zmÄ›n.

**Debugging a analÃ½za:** KdyÅ¾ recognition selÅ¾e (vrÃ¡tÃ­ Å¡patnÃ½ vÃ½sledek), potÅ™ebujeme bÃ½t schopni pÅ™esnÄ› reprodukovat problÃ©m aby ho Å¡lo analyzovat. S non-deterministickÃ½m systÃ©mem by stejnÃ½ sken nÄ›kdy fungoval sprÃ¡vnÄ› a nÄ›kdy ne, coÅ¾ by debugging ztÃ­Å¾ilo aÅ¾ znemoÅ¾nilo.

**Konzistence v produkci:** V produkÄnÃ­m nasazenÃ­ oÄekÃ¡vÃ¡me Å¾e pokud uÅ¾ivatel nahraje stejnÃ½ sken vÃ­cekrÃ¡t, dostane stejnÃ½ vÃ½sledek. Non-deterministickÃ© chovÃ¡nÃ­ by vedlo k frustraci uÅ¾ivatelÅ¯ ("vÄera to Å™Ã­kalo TD1 ZP42, dnes to Å™Ã­kÃ¡ TD1 ZP43").

DeterministickÃ© chovÃ¡nÃ­ zajiÅ¡Å¥ujeme nÄ›kolika mechanismy:

**FixnÃ­ seed pro projekÄnÃ­ hlavu:** ProjekÄnÃ­ hlava embedding modelu je inicializovanÃ¡ s `torch.manual_seed(12345)` pÅ™ed vytvoÅ™enÃ­m vrstev. TÃ­m zajistÃ­me Å¾e vÅ¡echny random inicializace vÃ¡h jsou identickÃ©.

**L2 normalizace embeddingÅ¯:** VÅ¡echny embedding vektory jsou L2-normalizovanÃ© na normu 1.0. To eliminuje variabilitu v dÃ©lce vektoru a zajiÅ¡Å¥uje Å¾e cosine similarity je deterministickÃ¡ operace.

**DeterministickÃ½ warp:** HomografickÃ¡ matice pro warp transformaci je vypoÄÃ­tanÃ¡ z quad pomocÃ­ fixed point arithmetic, takÅ¾e numerickÃ© zaokrouhlovacÃ­ chyby jsou minimÃ¡lnÃ­ a konzistentnÃ­.

**Å½Ã¡dnÃ© random augmentace:** Na rozdÃ­l od trÃ©novÃ¡nÃ­, v inference mÃ³du nepouÅ¾Ã­vÃ¡me Å¾Ã¡dnÃ© random augmentace (flip, rotate, color jitter). Vstup je zpracovÃ¡n vÅ¾dy stejnÄ›.

### L2 normalizace a cosine similarity

VÅ¡echny embedding vektory (jak query tak reference) jsou L2-normalizovanÃ© coÅ¾ znamenÃ¡ Å¾e jejich euklidovskÃ¡ norma je pÅ™esnÄ› 1.0. Matematicky: `||v|| = sqrt(v[0]^2 + v[1]^2 + ... + v[511]^2) = 1.0`.

L2 normalizace mÃ¡ dva dÅ¯leÅ¾itÃ© dÅ¯sledky:

**Cosine similarity = dot product:** Pro dva L2-normalizovanÃ© vektory a, b platÃ­: `cosine_similarity(a, b) = dot(a, b) / (||a|| * ||b||) = dot(a, b) / (1.0 * 1.0) = dot(a, b)`. Cosine similarity se tedy redukuje na prostÃ½ skalÃ¡rnÃ­ souÄin (dot product). Dot product je vÃ½raznÄ› rychlejÅ¡Ã­ neÅ¾ vÃ½poÄet cosine similarity - na CPU jde o Å™Ã¡dovÄ› 10Ã— speedup, na GPU jeÅ¡tÄ› vÃ­ce.

**Hodnoty v rozsahu [-1, 1]:** Dot product dvou L2-normalizovanÃ½ch vektorÅ¯ je vÅ¾dy v rozsahu [-1, 1] kde 1 znamenÃ¡ identickÃ© vektory (Ãºhel 0Â°), 0 znamenÃ¡ ortogonÃ¡lnÃ­ vektory (Ãºhel 90Â°), -1 znamenÃ¡ opaÄnÃ© vektory (Ãºhel 180Â°). V praxi se embedding vektory znÃ¡mek pohybujÃ­ v rozsahu 0.7-0.98 - nikdy nejsou opaÄnÃ© nebo ortogonÃ¡lnÃ­.

L2 normalizace se provÃ¡dÃ­ po projekci z 2048D na 512D:
```python
embedding = projection_head(resnet_features)  # (512,)
embedding = embedding / torch.norm(embedding)  # L2 normalize
```

VÅ¡echny referenÄnÃ­ embeddings v databÃ¡zi jsou uloÅ¾enÃ© uÅ¾ L2-normalizovanÃ© takÅ¾e pÅ™i matchingu staÄÃ­ naÄÃ­st vektor z BLOB a spoÄÃ­tat dot product - nenÃ­ potÅ™eba Å¾Ã¡dnÃ¡ dalÅ¡Ã­ normalizace.

### AgregaÄnÃ­ statistiky - mean, median, min, max

Pro kaÅ¾dÃ©ho kandidÃ¡ta (kombinaci TD + ZP) mÃ¡me nÄ›kolik similarity scores - jeden pro kaÅ¾dÃ½ crop kterÃ½ byl matchovanÃ½. Tyto scores agregujeme do statistik kterÃ© popisujÃ­ celkovou podobnost kandidÃ¡ta.

**Mean (prÅ¯mÄ›r)** je primÃ¡rnÃ­ metrika pro ranking kandidÃ¡tÅ¯. VypoÄÃ­tÃ¡ se jako aritmetickÃ½ prÅ¯mÄ›r vÅ¡ech similarity scores pro danÃ©ho kandidÃ¡ta. Mean dÃ¡vÃ¡ vÅ¡em crops stejnou vÃ¡hu - spirÃ¡la, obloha a keÅ™ jsou stejnÄ› dÅ¯leÅ¾itÃ©. KandidÃ¡ti jsou seÅ™azenÃ­ sestupnÄ› podle mean - ÄÃ­m vyÅ¡Å¡Ã­ prÅ¯mÄ›r, tÃ­m podobnÄ›jÅ¡Ã­ kandidÃ¡t.

**Median (mediÃ¡n)** je robustnÄ›jÅ¡Ã­ neÅ¾ mean vÅ¯Äi outliers. Pokud mÃ¡ kandidÃ¡t jeden crop s velmi nÃ­zkou similarity (outlier) zatÃ­mco ostatnÃ­ jsou vysokÃ©, mean klesne vÃ½raznÄ› ale median zÅ¯stane vysokÃ½. Median je uÅ¾iteÄnÃ½ pro identifikaci kandidÃ¡tÅ¯ kde vÄ›tÅ¡ina crops matchuje dobÅ™e ale jeden Äi dva jsou off.

**Min (minimum)** ukazuje nejhorÅ¡Ã­ match mezi vÅ¡emi crops. NÃ­zkÃ© minimum (napÅ™Ã­klad < 0.80) naznaÄuje Å¾e alespoÅˆ jeden crop matchuje Å¡patnÄ›, coÅ¾ mÅ¯Å¾e bÃ½t red flag pro false positive. Naopak vysokÃ© minimum (> 0.88) naznaÄuje konzistentnÄ› dobrÃ© matchovÃ¡nÃ­ across all crops.

**Max (maximum)** ukazuje nejlepÅ¡Ã­ match. VysokÃ© maximum (> 0.95) znamenÃ¡ Å¾e alespoÅˆ jeden crop matchuje velmi dobÅ™e. Ale pozor - high max s low min naznaÄuje nekonzistentnÃ­ matching kterÃ½ mÅ¯Å¾e bÃ½t false positive.

**Std (smÄ›rodatnÃ¡ odchylka)** mÄ›Å™Ã­ variabilitu similarity scores. NÃ­zkÃ¡ std (< 0.02) znamenÃ¡ Å¾e vÅ¡echny crops majÃ­ podobnou similarity - kandidÃ¡t matchuje konzistentnÄ›. VysokÃ¡ std (> 0.05) znamenÃ¡ velkÃ© rozdÃ­ly mezi crops - nÄ›kterÃ© matchujÃ­ dobÅ™e, jinÃ© Å¡patnÄ›. VysokÃ¡ std je warning sign.

**n (count)** je poÄet crops kterÃ© byly porovnanÃ©. Typicky n=4-8 podle drawing_id. Pokud je n vÃ½raznÄ› niÅ¾Å¡Ã­ neÅ¾ expected (napÅ™Ã­klad n=2 mÃ­sto 5), znamenÃ¡ to Å¾e nÄ›kterÃ© crops chybÄ›ly v databÃ¡zi nebo matchovÃ¡nÃ­ selhalo.

PÅ™Ã­klad interpretace:
```
KandidÃ¡t A: mean=0.92, median=0.91, min=0.89, max=0.94, std=0.018, n=5
â†’ Velmi dobrÃ½ match - vÅ¡echny crops konzistentnÄ› vysokÃ©

KandidÃ¡t B: mean=0.88, median=0.89, min=0.75, max=0.95, std=0.078, n=5
â†’ NekonzistentnÃ­ match - nÄ›kterÃ© crops dobÅ™e, jinÃ© Å¡patnÄ›
â†’ MoÅ¾nÃ½ false positive nebo damaged scan
```

---

## âš ï¸ DÅ®LEÅ½ITÃ PRAVIDLA

### Pravidlo 1: Preprocessing MUSÃ bÃ½t identickÃ½ s compute_reference_embeddings.py

Recognition pipeline a program `compute_reference_embeddings.py` (kterÃ½ vypoÄÃ­tÃ¡vÃ¡ referenÄnÃ­ embeddings pro databÃ¡zi) musÃ­ pouÅ¾Ã­vat naprosto identickÃ© preprocessing kroky. JakÃ½koliv rozdÃ­l v preprocessing vede k neporovnatelnÃ½m embeddingÅ¯m a recognition selÅ¾e.

**ProÄ je to kritickÃ©:**
Embedding reprezentace zÃ¡visÃ­ na tom jak byl vstupnÃ­ crop preprocessovanÃ½. Pokud referenÄnÃ­ embeddings byly vypoÄÃ­tanÃ© s jednÃ­m preprocessing (napÅ™. normalizace mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) a query embeddings s jinÃ½m (napÅ™. normalizace [0, 1]), vektory leÅ¾Ã­ v rÅ¯znÃ½ch regionech 512D prostoru a jejich podobnost nenÃ­ interpretovatelnÃ¡.

**Co musÃ­ bÃ½t identickÃ©:**
- **Warp target size:** 1300Ã—1100 pixelÅ¯ (pevnÄ› danÃ©)
- **Color space:** BGR (OpenCV default), konverze BGRâ†’RGB uvnitÅ™ encoderu
- **Crop extraction:** StejnÃ© relativnÃ­ souÅ™adnice, padding, polarity
- **Resize:** 224Ã—224 pÅ™ed ResNet50 (pevnÄ› danÃ© ResNet50 vstupem)
- **Normalizace:** Pouze dÄ›lenÃ­ 255.0 â†’ rozsah [0, 1], Å½ÃDNÃ ImageNet normalizace
- **Embedding model:** StejnÃ½ ResNet50 model se stejnou projekÄnÃ­ hlavou (stejnÃ½ seed!)
- **L2 normalizace:** AplikovanÃ¡ vÅ¾dy na konci

**Jak zajistit konzistenci:**
Oba programy pouÅ¾Ã­vajÃ­ stejnÃ½ `RealEncoder` class z `common/embedding_utils.py` kterÃ½ mÃ¡ preprocessing zabudovanÃ½ uvnitÅ™. To zajiÅ¡Å¥uje Å¾e preprocessing je vÅ¾dy identickÃ½ - nenÃ­ moÅ¾nÃ© nÃ¡hodou pouÅ¾Ã­t jinÃ© parametry.

**Kontrola konzistence:**
PÅ™i zmÄ›nÄ› preprocessing (napÅ™Ã­klad zmÄ›na warp size nebo normalizace) je NUTNÃ‰ pÅ™epoÄÃ­tat vÅ¡echny referenÄnÃ­ embeddings v databÃ¡zi. Nelze mÃ­chat starÃ© embeddings s novÃ½mi - buÄ vÅ¡e starÃ© nebo vÅ¡e novÃ©.

**âœ… SprÃ¡vnÄ›:**
```python
# recognize_stamp.py
from common.embedding_utils import RealEncoder
encoder = RealEncoder(model_path, head_path, seed=12345)
query_emb = encoder(crop_img)  # Preprocessing uvnitÅ™

# compute_reference_embeddings.py
from common.embedding_utils import RealEncoder
encoder = RealEncoder(model_path, head_path, seed=12345)
ref_emb = encoder(crop_img)  # STEJNÃ preprocessing
```

**âŒ Å patnÄ›:**
```python
# recognize_stamp.py - custom preprocessing
crop_normalized = (crop_img / 255.0 - [0.485, 0.456, 0.406]) / [0.229, 0.224, 0.225]
query_emb = model(crop_normalized)

# compute_reference_embeddings.py - jinÃ½ preprocessing
crop_normalized = crop_img / 255.0  # JinÃ¡ normalizace!
ref_emb = model(crop_normalized)

# â†’ Embeddings neporovnatelnÃ©!
```

### Pravidlo 2: ProjekÄnÃ­ hlava MUSÃ bÃ½t naÄtena z .pth souboru

ProjekÄnÃ­ hlava (2048D â†’ 512D neuronovÃ¡ sÃ­Å¥) musÃ­ bÃ½t VÅ½DY naÄtena z .pth souboru kterÃ½ obsahuje pÅ™edtrÃ©novanÃ© vÃ¡hy. Nikdy nesmÃ­ bÃ½t inicializovÃ¡na nÃ¡hodnÄ› nebo jinak neÅ¾ z .pth souboru uloÅ¾enÃ©ho v databÃ¡zi.

**ProÄ je to kritickÃ©:**
ProjekÄnÃ­ hlava je natrÃ©novanÃ¡ neuronovÃ¡ sÃ­Å¥ kterÃ¡ se nauÄila optimÃ¡lnÃ­ redukci dimenze pro rozliÅ¡ovÃ¡nÃ­ ÄeskoslovenskÃ½ch znÃ¡mek. NÃ¡hodnÃ¡ inicializace by dala kompletnÄ› jinÃ© embeddings kterÃ© nemajÃ­ Å¾Ã¡dnÃ½ vztah k embeddings v databÃ¡zi. Recognition by pak fungoval nÃ¡hodnÄ› - jako hÃ¡zenÃ­ mincÃ­.

**Jak funguje naÄÃ­tÃ¡nÃ­:**
```python
# 1. NaÄti head_path a seed z databÃ¡ze (model_embed_head tabulka)
head_row = conn.execute(
    "SELECT head_path, seed FROM model_embed_head WHERE model_id = ?",
    (model_id,)
).fetchone()

# 2. Nastav fixnÃ­ seed pro deterministickou strukturu
torch.manual_seed(head_row['seed'])  # Typicky 12345

# 3. VytvoÅ™ strukturu sÃ­tÄ› (vrstvy)
head = nn.Sequential(
    nn.Linear(2048, 512),
    nn.ReLU(),
    nn.Dropout(0.1)
)

# 4. NaÄti trÃ©novanÃ© vÃ¡hy z .pth souboru
head.load_state_dict(torch.load(head_row['head_path']))

# 5. Nastav eval() mÃ³d
head.eval()
```

**Seed je dÅ¯leÅ¾itÃ½ pro strukturu:**
Seed se nastavuje PÅ˜ED vytvoÅ™enÃ­m vrstev protoÅ¾e nÄ›kterÃ© vrstvy (napÅ™Ã­klad Dropout) pouÅ¾Ã­vajÃ­ random inicializaci. Se stejnÃ½m seedem dostaneme stejnou strukturu. Ale pozor - seed ovlivnÃ­ jen strukturu, ne vÃ¡hy! VÃ¡hy jsou naÄtenÃ© z .pth souboru a ty uÅ¾ seed neovlivnÃ­.

**Verifikace sprÃ¡vnosti:**
.pth soubor mÃ¡ v databÃ¡zi uloÅ¾enÃ½ SHA256 hash. PÅ™ed pouÅ¾itÃ­m mÅ¯Å¾eme verifikovat Å¾e soubor je nepoÅ¡kozenÃ½:
```python
import hashlib

with open(head_path, 'rb') as f:
    file_hash = hashlib.sha256(f.read()).hexdigest()

if file_hash != head_row['head_sha256']:
    raise ValueError("Projection head file corrupted or wrong version!")
```

**âœ… SprÃ¡vnÄ›:**
```python
torch.manual_seed(12345)
head = create_projection_head()
head.load_state_dict(torch.load('head.pth'))
```

**âŒ Å patnÄ›:**
```python
torch.manual_seed(12345)
head = create_projection_head()
# ChybÃ­ load_state_dict! PouÅ¾Ã­vÃ¡ random vÃ¡hy!
```

### Pravidlo 3: Å½ÃDNÃ ImageNet normalizace v inference

PÅ™i vÃ½poÄtu embeddingÅ¯ v inference mÃ³du NIKDY nesmÃ­me pouÅ¾Ã­t ImageNet normalizaci (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]). PouÅ¾Ã­vÃ¡me pouze prostou normalizaci dÄ›lenÃ­m 255.0 kterÃ¡ pÅ™evede pixely z rozsahu [0, 255] do rozsahu [0, 1].

**ProÄ je to kritickÃ©:**
ImageNet normalizace je standardnÃ­ preprocessing pro modely trÃ©novanÃ© na ImageNet datasetu. Ale nÃ¡Å¡ embedding model byl fine-tunovanÃ½ na ÄeskoslovenskÃ© znÃ¡mky s jinou normalizacÃ­. Pokud bychom pouÅ¾ili ImageNet normalizaci, preprocessing by se liÅ¡il od toho kterÃ½ byl pouÅ¾it pÅ™i fine-tuningu a embeddings by byly Å¡patnÃ©.

**Co je ImageNet normalizace:**
```python
# ImageNet normalizace (NEPOUÅ½ÃVAT!)
mean = [0.485, 0.456, 0.406]  # RGB channels
std = [0.229, 0.224, 0.225]
normalized = (image - mean) / std
```

Tato normalizace posunuje a Å¡kÃ¡luje pixely aby mÄ›ly podobnÃ© statistiky jako ImageNet dataset. Ale naÅ¡e znÃ¡mky majÃ­ jinÃ© statistiky - napÅ™Ã­klad vÃ­ce Å¡edÃ½ch tÃ³nÅ¯ a mÃ©nÄ› saturovanÃ½ch barev neÅ¾ fotky z ImageNetu.

**Co mÃ­sto toho pouÅ¾Ã­vÃ¡me:**
```python
# NaÅ¡e normalizace (SPRÃVNÄš)
normalized = image / 255.0  # [0, 255] â†’ [0, 1]
```

ProstÃ¡ normalizace do rozsahu [0, 1] zachovÃ¡vÃ¡ relativnÃ­ intenzity pixelÅ¯ beze zmÄ›ny. To je pÅ™esnÄ› to co chceme - embeddings jsou pak konzistentnÃ­ s referenÄnÃ­mi embeddings kterÃ© byly vypoÄÃ­tanÃ© stejnÃ½m zpÅ¯sobem.

**Kde je normalizace implementovanÃ¡:**
Normalizace je zabudovanÃ¡ uvnitÅ™ `RealEncoder.__call__()` metody takÅ¾e programÃ¡tor ji nemÅ¯Å¾e nÃ¡hodou udÄ›lat Å¡patnÄ›:
```python
class RealEncoder:
    def __call__(self, crop_bgr: np.ndarray) -> np.ndarray:
        # BGR â†’ RGB
        crop_rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)
        
        # Resize
        crop_resized = cv2.resize(crop_rgb, (224, 224))
        
        # Normalizace [0,255] â†’ [0,1]
        crop_float = crop_resized.astype(np.float32) / 255.0  # â† TADY
        
        # PyTorch tensor
        crop_tensor = torch.from_numpy(crop_float).permute(2, 0, 1)
        
        # Forward pass
        ...
```

**âœ… SprÃ¡vnÄ›:**
```python
crop_normalized = crop_bgr / 255.0
```

**âŒ Å patnÄ›:**
```python
mean = [0.485, 0.456, 0.406]
std = [0.229, 0.224, 0.225]
crop_normalized = (crop_bgr / 255.0 - mean) / std  # NEPOUÅ½ÃVAT!
```

### Pravidlo 4: Matching pouze v rÃ¡mci stejnÃ© kresby (drawing_id)

PÅ™i matching query embeddingÅ¯ s referenÄnÃ­mi embeddingy MUSÃME porovnÃ¡vat pouze embeddings ze stejnÃ© kresby (drawing_id). Nelze porovnÃ¡vat znÃ¡mku s kresbou "s popisem" proti znÃ¡mce s kresbou "abstraktnÃ­".

**ProÄ je to kritickÃ©:**
RÅ¯znÃ© kresby majÃ­ rÅ¯znÃ© crops - napÅ™Ã­klad kresba "s popisem" mÃ¡ crop na pozici nÃ¡pisu POÅ TA, zatÃ­mco kresba "abstraktnÃ­" tento crop nemÃ¡. Embeddings rÅ¯znÃ½ch crops leÅ¾Ã­ v rÅ¯znÃ½ch regionech 512D prostoru a jejich podobnost nenÃ­ interpretovatelnÃ¡. PorovnÃ¡vat "nÃ¡pis POÅ TA" vs "spirÃ¡la" by bylo jako porovnÃ¡vat jablka s pomeranÄi.

**Jak se urÄuje drawing_id:**
Drawing_id je odvozenÃ© z denomination (typu znÃ¡mky). KaÅ¾dÃ½ typ znÃ¡mky mÃ¡ pÅ™iÅ™azenou konkrÃ©tnÃ­ kresbu v databÃ¡zovÃ© tabulce `stamp_types`:
```sql
SELECT drawing_id FROM stamp_types WHERE id = stamp_type_id;
```

NapÅ™Ã­klad znÃ¡mka 500h mÃ¡ drawing_id=5 (abstraktnÃ­ kresba), znÃ¡mka 10h5 mÃ¡ drawing_id=1 (s popisem). Po urÄenÃ­ denomination (buÄ manuÃ¡lnÄ› nebo auto-detect) vÃ­me drawing_id a mÅ¯Å¾eme naÄÃ­st pÅ™Ã­sluÅ¡nÃ© crops.

**Enforcement v SQL query:**
```sql
-- Matching query embedding crop_id=8 (spirala_levy)
SELECT 
    re.scan_id,
    rf.plate_id,
    rf.zp_no,
    dot_product(re.vec, ?) AS similarity
FROM reference_embeddings re
JOIN reference_front rf ON re.scan_id = rf.id
WHERE 
    re.crop_id = 8                    -- STEJNÃ crop
    AND rf.drawing_id = ?             -- â† STEJNÃ kresba (enforcement)
    AND rf.confirmed = 1
ORDER BY similarity DESC;
```

Drawing_id je pÅ™edanÃ½ jako parametr do query aby se filtroval pouze embeddings ze stejnÃ© kresby.

**Co se stane pÅ™i poruÅ¡enÃ­:**
Pokud bychom matchovali napÅ™Ã­Ä kresbami, dostali bychom nesmyslnÃ© vÃ½sledky - napÅ™Ã­klad znÃ¡mka 500h (abstraktnÃ­) by mohla matchovat s 10h5 (s popisem) protoÅ¾e nÃ¡hodou nÄ›kterÃ© embeddings jsou v podobnÃ©m regionu prostoru. Recognition by selhal s nepÅ™edvÃ­datelnÃ½mi vÃ½sledky.

**âœ… SprÃ¡vnÄ›:**
```python
# Query mÃ¡ drawing_id=5 (500h, abstraktnÃ­)
# Matching pouze proti drawing_id=5
matches = match_embeddings(conn, query_embs, drawing_id=5)
```

**âŒ Å patnÄ›:**
```python
# Matching proti VÅ EM drawing_id - CHYBA!
matches = match_embeddings(conn, query_embs, drawing_id=None)
```

---

## ğŸ› ZNÃMÃ‰ PROBLÃ‰MY / OMEZENÃ

### ProblÃ©m 1: OCR selhÃ¡vÃ¡ na 1000h znÃ¡mkÃ¡ch (58% pÅ™esnost)

OCR model (EasyOCR) mÃ¡ vÃ½raznÄ› niÅ¾Å¡Ã­ pÅ™esnost na znÃ¡mkÃ¡ch 1000h ve srovnÃ¡nÃ­ s ostatnÃ­mi typy. Na testovacÃ­m datasetu dosahuje pouze 58% ÃºspÄ›Å¡nosti rozpoznÃ¡nÃ­ textu "1000" z hodnotovÃ©ho Å¡tÃ­tku. U ostatnÃ­ch denominacÃ­ je OCR pÅ™esnost typicky > 95%.

**ProÄ to selhÃ¡vÃ¡:**
HodnotovÃ½ Å¡tÃ­tek na 1000h znÃ¡mce obsahuje ÄtyÅ™i ÄÃ­slice "1000" vytiÅ¡tÄ›nÃ© relativnÄ› malÃ½m fontem. Nuly Äasto splÃ½vajÃ­ dohromady nebo se Ätou jako pÃ­smeno "O". EasyOCR model Äte text jako "100", "10O0", "1OOO" nebo "IO00" - tedy s rÅ¯znÃ½mi variacemi zÃ¡mÄ›ny nula/O. Pro parsing je pak tÄ›Å¾kÃ© urÄit jestli jde o 1000h nebo o nÄ›co jinÃ©ho.

**Dopad na recognition:**
Multi-phase detection pouÅ¾Ã­vÃ¡ OCR jako sekundÃ¡rnÃ­ metodu pro disambiguation. KdyÅ¾ OCR selÅ¾e, spolÃ©hÃ¡me pouze na embedding similarity. Pro 1000h to znamenÃ¡ Å¾e auto-detect mÅ¯Å¾e mÃ­t niÅ¾Å¡Ã­ confidence nebo v edge cases vybrat Å¡patnÃ©ho kandidÃ¡ta. V praxi dÃ­ky vysokÃ© embedding similarity (> 0.90) recognition stÃ¡le funguje relativnÄ› dobÅ™e (celkovÃ¡ success rate 96.9%), ale nenÃ­ to ideÃ¡lnÃ­.

**MoÅ¾nÃ¡ Å™eÅ¡enÃ­:**
1. **VÄ›tÅ¡Ã­ crop:** ZvÄ›tÅ¡it crop hodnotovÃ©ho Å¡tÃ­tku aby ÄÃ­slice byly vÄ›tÅ¡Ã­ a lÃ©pe ÄitelnÃ©
2. **OCR preprocessing:** PÅ™edzpracovat crop (contrast enhancement, denoising) pÅ™ed OCR
3. **Specialized OCR:** NatrÃ©novat vlastnÃ­ OCR model specificky na ÄeskoslovenskÃ© znÃ¡mky
4. **Pattern matching:** MÃ­sto obecnÃ©ho OCR pouÅ¾Ã­t template matching pro specifickÃ© fonty
5. **Trust embeddings:** PÅ™i detection 1000h trusted vÃ­ce embedding similarity neÅ¾ OCR

**Workaround:**
AktuÃ¡lnÄ› pouÅ¾Ã­vÃ¡me workaround kde pokud OCR pÅ™eÄte "100" nebo podobnÃ© varianty a embedding similarity je vysokÃ¡ (> 0.88), pÅ™idÃ¡vÃ¡me 1000h jako dodateÄnÃ©ho kandidÃ¡ta. To zlepÅ¡ilo accuracy z 58% na 78%, ale stÃ¡le nenÃ­ perfektnÃ­.

### ProblÃ©m 2: 15h TD4 mÃ¡ nÃ­zkou ÃºspÄ›Å¡nost (~5%)

ZnÃ¡mka 15h tiskovÃ¡ deska TD4 mÃ¡ extrÃ©mnÄ› nÃ­zkou recognition accuracy (~5%) ve srovnÃ¡nÃ­ s ostatnÃ­mi deskami tÃ©Å¾e znÃ¡mky (TD1-3 dosahujÃ­ 95-98%). JednÃ¡ se o systematickÃ½ problÃ©m specifickÃ½ pouze pro TD4.

**ProÄ to selhÃ¡vÃ¡:**
ReferenÄnÃ­ skeny TD4 v databÃ¡zi majÃ­ vÃ½raznÄ› horÅ¡Ã­ kvalitu neÅ¾ TD1-3. VÄ›tÅ¡ina TD4 skenÅ¯ pochÃ¡zÃ­ z jednoho zdroje (pravdÄ›podobnÄ› amatÃ©rskÃ½ scan) a jsou rozmazanÃ©, majÃ­ Å¡patnÃ© osvÄ›tlenÃ­ nebo nÃ­zkÃ© rozliÅ¡enÃ­. Embeddings vypoÄÃ­tanÃ© z takovÃ½ch skenÅ¯ nejsou reprezentativnÃ­ pro kvalitnÃ­ TD4 exemplÃ¡Å™e.

KdyÅ¾ pak analyzujeme kvalitnÃ­ TD4 sken, jeho embeddings se neporovnÃ¡vajÃ­ dobÅ™e s low-quality referenÄnÃ­mi embeddings v databÃ¡zi. Recognition systÃ©m pak matchuje proti TD1-3 kterÃ© majÃ­ quality reference skeny, mÃ­sto sprÃ¡vnÃ© TD4.

**Dopad:**
TD4 znÃ¡mky jsou velmi vzÃ¡cnÃ© ve srovnÃ¡nÃ­ s TD1-3, takÅ¾e tento problÃ©m ovlivÅˆuje pouze malÃ© procento celkovÃ©ho datasetu. Na celkovÃ© accuracy 96.9% mÃ¡ TD4 problÃ©m minimÃ¡lnÃ­ vliv. Ale pro uÅ¾ivatele kteÅ™Ã­ majÃ­ TD4 exemplÃ¡Å™ je to frustrujÃ­cÃ­ - systÃ©m jim vrÃ¡tÃ­ Å¡patnÃ½ vÃ½sledek.

**MoÅ¾nÃ¡ Å™eÅ¡enÃ­:**
1. **Rescan TD4:** ZÃ­skat high-quality skeny TD4 exemplÃ¡Å™Å¯ a nahradit jimi low-quality reference
2. **Quality filtering:** Automaticky detekovat low-quality skeny a vyÅ™adit je z databÃ¡ze
3. **Quality normalization:** Preprocessing kterÃ½ normalizuje rozdÃ­ly v kvalitÄ› (deblurring, enhancement)
4. **Separate handling:** SpecifickÃ© parametry nebo threshold pro TD4 matching

**Status:**
Priorita LOW protoÅ¾e ovlivÅˆuje pouze malÃ© procento pÅ™Ã­padÅ¯. PlÃ¡novanÃ© Å™eÅ¡enÃ­ je rescan TD4 - zÃ­skat 10-20 high-quality TD4 exemplÃ¡Å™Å¯ ze spolehlivÃ©ho zdroje a nahradit jimi souÄasnÃ© reference. To by mÄ›lo accuracy zlepÅ¡it z 5% na oÄekÃ¡vanÃ½ch 95%+.

### ProblÃ©m 3: False positives pÅ™i poÅ¡kozenÃ½ch skenech

Recognition pipeline mÃ¡ tendenci produkovat false positives kdyÅ¾ je vstupnÃ­ sken vÃ½raznÄ› poÅ¡kozenÃ½, rozmazanÃ½ nebo mÃ¡ velkÃ© neÄistoty. NapÅ™Ã­klad sken s velkÃ½m zÃ¡hybem pÅ™es stÅ™ed znÃ¡mky mÅ¯Å¾e matchovat s vysokou confidence proti nesprÃ¡vnÃ©mu kandidÃ¡tovi.

**ProÄ to selhÃ¡vÃ¡:**
Embeddings jsou relativnÄ› robustnÃ­ vÅ¯Äi malÃ½m defektÅ¯m (drobnÃ© Å¡krÃ¡bance, dust particles) ale vÃ½raznÃ© poÅ¡kozenÃ­ mÅ¯Å¾e zmÄ›nit embedding reprezentaci natolik Å¾e pÅ™ipomÃ­nÃ¡ jinou znÃ¡mku. Pokud je napÅ™Ã­klad spirÃ¡la zakrytÃ¡ zÃ¡hybem, jejÃ­ embedding se zmÄ›nÃ­ a mÅ¯Å¾e nÃ¡hodou matchovat spirÃ¡lu z jinÃ©ho ZP.

AgregaÄnÃ­ statistiky (mean, median, min, max) ÄÃ¡steÄnÄ› pomÃ¡hajÃ­ identifikovat takovÃ© pÅ™Ã­pady - pokud mÃ¡ kandidÃ¡t vysokou varianci (std > 0.05) nebo nÃ­zkÃ© minimum (< 0.80), je to warning sign. Ale nenÃ­ to dokonalÃ© Å™eÅ¡enÃ­.

**Dopad:**
OdhadovanÃ¡ frekvence je < 1% (na 6800 testovacÃ­ch skenÅ¯ < 50 false positives). VÄ›tÅ¡inou jde o edge cases kde sken je skuteÄnÄ› v very poor condition. V produkÄnÃ­m nasazenÃ­ je dÅ¯leÅ¾itÃ© aby uÅ¾ivatel mohl false positive reportovat pro review.

**MoÅ¾nÃ¡ Å™eÅ¡enÃ­:**
1. **Quality detection:** PÅ™ed recognition detekovat quality skenu a varovat uÅ¾ivatele
2. **Confidence thresholds:** PÅ™i nÃ­zkÃ© confidence (mean < 0.85 or std > 0.05) vrÃ¡tit "uncertain" mÃ­sto top candidate
3. **Manual review flag:** Automaticky flagovat suspicious results pro expert review
4. **Multiple scans:** PoÅ¾Ã¡dat uÅ¾ivatele o multiple skeny ze stejnÃ© znÃ¡mky a agregovat vÃ½sledky

**Workaround:**
AktuÃ¡lnÄ› vizuÃ¡lnÃ­ mozaika (FÃZE 14) umoÅ¾Åˆuje uÅ¾ivateli vizuÃ¡lnÄ› zkontrolovat jestli TOP-1 kandidÃ¡t opravdu vypadÃ¡ podobnÄ›. To nenÃ­ automatickÃ© ale alespoÅˆ dÃ¡vÃ¡ moÅ¾nost odhalit false positive before commit.

---

## ğŸ”— SOUVISLOSTI

### ImplementovÃ¡no v

**recognize_stamp.py v3.2.0** - ProdukÄnÃ­ implementace recognition pipeline. HlavnÃ­ program pro rozpoznÃ¡vÃ¡nÃ­ znÃ¡mek z command line. Implementuje vÅ¡ech 14 fÃ¡zÃ­ pipeline pÅ™esnÄ› jak je popsÃ¡no v tomto dokumentu.

**compute_reference_embeddings.py** - Program pro vÃ½poÄet referenÄnÃ­ch embeddingÅ¯ kterÃ© se uklÃ¡dajÃ­ do databÃ¡ze. PouÅ¾Ã­vÃ¡ IDENTICKÃ‰ preprocessing jako recognize_stamp.py aby embeddings byly porovnatelnÃ©. Implementuje fÃ¡ze 1-2, 4, 6-7 (naÄtenÃ­ konfigurace, encoder init, warp, crops, embedding computation).

### PouÅ¾Ã­vÃ¡

**common/embedding_utils.py v1.3.0** - RealEncoder class kterÃ¡ zapouzdÅ™uje preprocessing a embedding computation. Obsahuje deterministickou projekÄnÃ­ hlavu, BGRâ†’RGB konverzi, normalizaci [0,1] a L2 normalizaci vÃ½stupu.

**common/denomination_utils.py v2.0.1** - Multi-phase auto-detect algoritmus kterÃ½ kombinuje embedding similarity, OCR a HSV color matching. PouÅ¾Ã­vanÃ½ ve FÃZI 5 pro automatickou detekci typu znÃ¡mky.

**common/ocr_utils.py v1.0.0** - EasyOCR wrapper pro extrakci textu z hodnotovÃ©ho Å¡tÃ­tku. PouÅ¾Ã­vanÃ½ v rÃ¡mci auto-detect workflow pro disambiguation podobnÃ½ch typÅ¯ (10h5 vs 15h).

**common/color_utils.py v1.0.0** - HSV color matching utilities pro verifikaci barvy znÃ¡mky. PouÅ¾Ã­vanÃ½ jako terciÃ¡rnÃ­ metoda v auto-detect workflow.

**common/yolo_utils.py v1.0.0** - YOLO detection wrapper pro detekci rÃ¡meÄkÅ¯ znÃ¡mek. PouÅ¾Ã­vanÃ½ ve FÃZI 3 pro hybrid detection workflow.

**common/db_utils.py v1.1.0** - CentralizovanÃ© databÃ¡zovÃ© operace (22 funkcÃ­) pro vÅ¡echny interakce s databÃ¡zÃ­. Eliminuje duplicitnÃ­ DB kÃ³d a zajiÅ¡Å¥uje konzistentnÃ­ pÅ™Ã­stup k datÅ¯m.

**common/load_config.py v1.9.1** - Path management a konfigurace environment (dev/prod/sandbox). Single source of truth pro vÅ¡echny cesty k modelÅ¯m, databÃ¡zi a datÅ¯m.

### NavazujÃ­cÃ­ dokumenty

**base/database_schema.md** - KompletnÃ­ dokumentace databÃ¡zovÃ© struktury vÄetnÄ› tabulek `reference_front`, `reference_embeddings`, `model_registry`, `model_embed_head`, `drawing_crops`. Popisuje jakÃ¡ data jsou kde uloÅ¾enÃ¡ a proÄ.

**decisions/realencoder_centralization.md** - RozhodnutÃ­ proÄ a jak jsme centralizovali embedding computation do RealEncoder class. VysvÄ›tluje rozdÃ­l mezi RealEncoder (wrapper s preprocessing) a ResNet50Embed (raw model).

**decisions/schema_v3_1_0_nullable_columns.md** - RozhodnutÃ­ o nullable metadata columns v DB schema v3.1.0. VysvÄ›tluje pending workflow kde skeny majÃ­ NULL metadata dokud nejsou potvrzeny expertem.

**decisions/gt_management_use_cases.md** - CelkovÃ½ koncept GT Management systÃ©mu (17 use cases, 4 workflows). Recognition pipeline je pouÅ¾itÃ½ v UC-2 (Confirm Classification) jako nÃ¡stroj pro analÃ½zu pending skenÅ¯.

**decisions/uc1_workflow.md** - DetailnÃ­ popis UC-1 Upload & Analyze workflow kterÃ½ je komplementÃ¡rnÃ­ k recognition pipeline. UC-1 Å™eÅ¡Ã­ file storage a deduplication, recognition pipeline Å™eÅ¡Ã­ samotnÃ© rozpoznÃ¡vÃ¡nÃ­.

---

**Tento dokument je zlatÃ½ standard pro recognition workflow. VÅ¡echny novÃ© implementace MUSÃ dodrÅ¾et fÃ¡ze 1-9. FÃ¡ze 10-14 jsou volitelnÃ© a mohou bÃ½t vynechÃ¡ny nebo nahrazeny podle potÅ™eby use case.**

---

**PoslednÃ­ aktualizace:** 2026-01-13  
**Autor:** Milan + Claude  
**Zdroj:** recognize_stamp.py v3.2.0  
**Status:** âœ… ACTIVE - PRODUCTION REFERENCE

