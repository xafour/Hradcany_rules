# RealEncoder Centralization

**Tags:** `#embedding` `#refactoring` `#single-source-of-truth`  
**Verze:** 1.0.0  
**Datum:** 2026-01-09  
**Status:** Active

---

## üéØ ROZHODNUT√ç

Rozhodli jsme se p≈ôesunout definici t≈ô√≠dy `RealEncoder` z `recognize_stamp.py` do centr√°ln√≠ho modulu `common/embedding_utils.py`. Tato zmƒõna byla provedena 2025-12-31 v r√°mci p≈ô√≠pravy na GT Management implementaci.

RealEncoder je wrapper kolem ResNet50 modelu, kter√Ω zaji≈°≈•uje konzistentn√≠ v√Ωpoƒçet embedding≈Ø - m√° zabudovan√© preprocessing (BGR ‚Üí RGB konverze, resize, normalizace), deterministickou projekƒçn√≠ hlavu (seed=12345), a L2 normalizaci v√Ωstupu. Je to kritick√° komponenta pro recognition syst√©m, proto≈æe mus√≠ garantovat ≈æe query zn√°mka a referenƒçn√≠ zn√°mky pou≈æ√≠vaj√≠ naprosto identick√Ω encoder - jak√Ωkoliv rozd√≠l v preprocessing nebo projekƒçn√≠ hlavƒõ by vedl k nekonzistentn√≠m embedding≈Øm a ≈°patn√Ωm v√Ωsledk≈Øm matchingu.

P≈ôed touto zmƒõnou byla t≈ô√≠da RealEncoder definovan√° p≈ô√≠mo v `recognize_stamp.py`, co≈æ fungovalo dokud byl recognition jedin√Ω use case. Ale s implementac√≠ GT Management jsme pot≈ôebovali stejn√Ω encoder i v `gt_upload_utils.py` (pro auto-detect denomination). Duplikovat k√≥d by bylo ≈°patn√© ≈ôe≈°en√≠ - p≈ôi jak√©koliv zmƒõnƒõ bychom museli pamatovat na update na dvou m√≠stech. Centralizace do `embedding_utils.py` zaji≈°≈•uje single source of truth.

---

## üîç KONTEXT A D≈ÆVODY

### Probl√©m s duplikac√≠

Kdy≈æ jsme zaƒçali implementovat UC-1 (Upload & Analyze), narazili jsme na probl√©m: pot≈ôebujeme vypoƒç√≠tat embeddings z nahran√©ho skenu a porovnat je s referenƒçn√≠mi embeddingy aby jsme mohli navrhnout klasifikaci. To vy≈æaduje stejn√Ω encoder jak√Ω pou≈æ√≠v√° `recognize_stamp.py`.

Prvn√≠ n√°pad byl zkop√≠rovat definici RealEncoder z `recognize_stamp.py` do `gt_upload_utils.py`. Ale to by vedlo k duplikaci ~50 ≈ô√°dk≈Ø k√≥du a k riziku divergence - co kdy≈æ pozdƒõji zmƒõn√≠me preprocessing v jednom souboru a zapomeneme to zmƒõnit v druh√©m? Embeddings by pak nebyly konzistentn√≠.

### RealEncoder vs ResNet50Embed

Je d≈Øle≈æit√© rozli≈°ovat mezi `ResNet50Embed` (raw PyTorch model) a `RealEncoder` (wrapper s preprocessing). ResNet50Embed oƒçek√°v√° PyTorch tensor na vstupu a vrac√≠ raw 2048-dimenzion√°ln√≠ vektor. RealEncoder oƒçek√°v√° numpy BGR array (jak ho vrac√≠ OpenCV) a vrac√≠ L2-normalizovan√Ω 512-dimenzion√°ln√≠ vektor (po pr≈Øchodu projekƒçn√≠ hlavou).

Kdyby jsme v `gt_upload_utils.py` pou≈æili p≈ô√≠mo ResNet50Embed m√≠sto RealEncoder, museli bychom duplikovat v≈°echen preprocessing k√≥d - BGR‚ÜíRGB konverzi, resize na 224√ó224, normalizaci, konverzi na tensor, naƒçten√≠ projekƒçn√≠ hlavy, forward pass, L2 normalizaci. To by bylo je≈°tƒõ hor≈°√≠ ne≈æ duplikovat cel√Ω RealEncoder.

### Single Source of Truth

Principem single source of truth je: ka≈æd√Ω kus logiky by mƒõl b√Ωt definovan√Ω na JEDNOM m√≠stƒõ. Kdy≈æ pot≈ôebujeme tu logiku na v√≠ce m√≠stech, importujeme ji, ne kop√≠rujeme.

Centralizace RealEncoder do `embedding_utils.py` znamen√°: (1) definice existuje na jednom m√≠stƒõ, (2) zmƒõny se automaticky projev√≠ v≈°ude kde se pou≈æ√≠v√°, (3) nem≈Ø≈æe doj√≠t k divergenci mezi instancemi, (4) snaz≈°√≠ testov√°n√≠ - testujeme jeden modul m√≠sto v√≠ce kopi√≠.

---

## üí° D≈ÆSLEDKY

### Backward Compatibility

P≈ôesun RealEncoder do `embedding_utils.py` nijak nenaru≈°il existuj√≠c√≠ funkƒçnost `recognize_stamp.py`. Zmƒõnili jsme pouze kde je RealEncoder definovan√Ω, ne jak funguje. `recognize_stamp.py` teƒè importuje RealEncoder m√≠sto toho aby ho definoval lok√°lnƒõ:

```python
# P≈ôed (recognize_stamp.py obsahoval definici):
class RealEncoder:
    def __init__(self, model_id, env):
        # ... 50 ≈ô√°dk≈Ø k√≥du ...

# Po (recognize_stamp.py importuje):
from common.embedding_utils import RealEncoder
```

V≈°echny testy `recognize_stamp.py` st√°le pro≈°ly, baseline validation (6,800 sken≈Ø) dala stejn√© v√Ωsledky. To potvrzuje ≈æe p≈ôesun byl clean refactoring bez zmƒõny chov√°n√≠.

### Nov√° funkcionalita v GT Management

`gt_upload_utils.py` teƒè m≈Ø≈æe pou≈æ√≠vat RealEncoder pro auto-detect denomination:

```python
from common.embedding_utils import RealEncoder

# V UC-1 workflow:
encoder = RealEncoder(model_id=model_id, env='dev')
query_embedding = encoder(warped_crop)  # numpy BGR ‚Üí 512D L2-normalized
# ... porovnej s reference embeddings ...
```

Proto≈æe je to STEJN√ù encoder jako pou≈æ√≠v√° `recognize_stamp.py`, m√°me garantov√°no ≈æe embeddings jsou konzistentn√≠. Query embedding z UC-1 lze p≈ô√≠mo porovnat s reference embeddings v datab√°zi.

### Code Elimination

Refactoring eliminoval ~50 ≈ô√°dk≈Ø duplicitn√≠ho k√≥du. `recognize_stamp.py` se zmen≈°il (import m√≠sto definice), `gt_upload_utils.py` nepot≈ôebuje duplikovat k√≥d, a `embedding_utils.py` se stal centr√°ln√≠m m√≠stem pro v≈°e co souvis√≠ s embeddingy.

---

## üîß TECHNICK√â DETAILY

### Co RealEncoder dƒõl√°

```python
class RealEncoder:
    def __init__(self, model_id: int, env: str):
        # 1. Naƒçte ResNet50 backbone
        self.backbone = load_resnet50()
        
        # 2. Naƒçte deterministickou projekƒçn√≠ hlavu (2048‚Üí512)
        self.head = load_projection_head(
            model_id=model_id,
            seed=12345  # FIXED seed pro determinismus
        )
        
    def __call__(self, crop_bgr: np.ndarray) -> np.ndarray:
        """
        Preprocessing + forward pass + L2 normalization.
        
        Input: numpy array (H, W, 3), BGR, uint8
        Output: numpy array (512,), float32, L2-normalized
        """
        # 1. BGR ‚Üí RGB
        crop_rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)
        
        # 2. Resize ‚Üí 224√ó224
        crop_resized = cv2.resize(crop_rgb, (224, 224))
        
        # 3. Normalize [0,1]
        crop_normalized = crop_resized / 255.0
        
        # 4. To tensor
        tensor = torch.from_numpy(crop_normalized).permute(2,0,1).unsqueeze(0)
        
        # 5. Forward pass: ResNet50 ‚Üí 2048D
        with torch.no_grad():
            features = self.backbone(tensor)  # (1, 2048)
        
        # 6. Projection head: 2048D ‚Üí 512D
        embedding = self.head(features)  # (1, 512)
        
        # 7. L2 normalization
        embedding_normalized = F.normalize(embedding, p=2, dim=1)
        
        # 8. To numpy
        return embedding_normalized.cpu().numpy()[0]  # (512,)
```

V≈°imni si ≈æe preprocessing je SOUƒå√ÅST√ç RealEncoder. Kdy≈æ vol√°me `encoder(crop)`, dost√°v√°me u≈æ kompletnƒõ zpracovan√Ω embedding. Nemus√≠me pamatovat na v≈°echny preprocessing kroky - RealEncoder to dƒõl√° automaticky.

### Proƒç deterministick√° projekƒçn√≠ hlava

Projekƒçn√≠ hlava (2048‚Üí512 linear layer) je inicializovan√° s FIXN√çM seedem (12345). To zaji≈°≈•uje ≈æe p≈ôi ka≈æd√©m naƒçten√≠ modelu dostaneme identickou hlavu - stejn√© v√°hy, stejn√Ω bias.

D≈Øvod: Referenƒçn√≠ embeddings v datab√°zi byly vypoƒç√≠tan√© s konkr√©tn√≠ projekƒçn√≠ hlavou. Pokud bychom query embeddings poƒç√≠tali s JINOU hlavou (n√°hodnƒõ inicializovanou), nebyly by porovnateln√©. Fixed seed zaji≈°≈•uje reprodukovatelnost.

---

## üîó SOUVISLOSTI

**Pou≈æ√≠v√°no v:**
- `recognize_stamp.py` v3.1.1 - Recognition pipeline
- `gt_upload_utils.py` v1.6.0 - UC-1 auto-detect
- `compute_reference_embeddings.py` - Baseline embeddings computation

**Technick√° dokumentace:**
- [base/pipeline_recognition.md](../base/pipeline_recognition.md) - Jak recognition pou≈æ√≠v√° RealEncoder

**Dal≈°√≠ rozhodnut√≠:**
- [decisions/uc1_workflow.md](./uc1_workflow.md) - Jak UC-1 pou≈æ√≠v√° RealEncoder pro auto-detect

**Implementace:**
- `common/embedding_utils.py` v1.3.0 - Centr√°ln√≠ definice
- Migration: 2025-12-31, verified by baseline tests

---

**Posledn√≠ aktualizace:** 2026-01-09  
**Autor:** Milan + Claude  
**Status:** ‚úÖ ACTIVE

---
