# SHA256 Storage Strategy

**Tags:** `#file-storage` `#sha256` `#deduplication`  
**Verze:** 1.0.0  
**Datum:** 2026-01-09  
**Status:** Active

---

## ğŸ¯ ROZHODNUTÃ

Rozhodli jsme se pouÅ¾Ã­vat SHA256 hash jako primÃ¡rnÃ­ identifikÃ¡tor souborÅ¯ v GT Management systÃ©mu. Soubory se uklÃ¡dajÃ­ do struktury `~/ProjektHradcany/<env>/gt_data/scans/<first2>/<sha256>_<type>.<ext>`, kde `<first2>` jsou prvnÃ­ dva znaky SHA256 hashu (00 aÅ¾ ff), coÅ¾ vytvÃ¡Å™Ã­ 256 subdirectories. Cesta k souboru se NEuklÃ¡dÃ¡ do databÃ¡ze - mÃ­sto toho se rekonstruuje z SHA256 hashu kdyÅ¾ je potÅ™eba.

Toto rozhodnutÃ­ Å™eÅ¡Ã­ nÄ›kolik problÃ©mÅ¯ najednou: (1) automatickÃ¡ deduplication - dva uÅ¾ivatelÃ© kteÅ™Ã­ nahrajÃ­ stejnÃ½ sken dostanou stejnÃ½ hash a systÃ©m poznÃ¡ duplicitu, (2) scalability - 256 subdirectories umoÅ¾Åˆuje uklÃ¡dat miliony souborÅ¯ bez performance degradace, (3) flexibilita - mÅ¯Å¾eme zmÄ›nit storage lokaci bez update databÃ¡ze, (4) multi-user safe - kaÅ¾dÃ½ uÅ¾ivatel "vlastnÃ­" svÅ¯j upload, ale fyzicky je uloÅ¾en jen jeden soubor.

SHA256 hash poÄÃ­tÃ¡me VÅ½DY z originÃ¡lnÃ­ho souboru, ne z transformovanÃ½ch verzÃ­ (warp). DÅ¯vod: dva uÅ¾ivatelÃ© kteÅ™Ã­ nahrajÃ­ stejnÃ½ originÃ¡lnÃ­ sken musÃ­ dostat stejnÃ½ hash. Pokud bychom hashovali transformaci, mohli by dostat mÃ­rnÄ› odliÅ¡nÃ© hashe kvÅ¯li rounding errors a deduplication by nefungovala.

---

## ğŸ” KONTEXT A DÅ®VODY

### ProblÃ©m s klasickÃ½m storage

KlasickÃ½ pÅ™Ã­stup k uklÃ¡dÃ¡nÃ­ souborÅ¯ je: kaÅ¾dÃ½ soubor mÃ¡ unikÃ¡tnÃ­ jmÃ©no (napÅ™Ã­klad `500hal_TD1_zp042.jpg`) a uklÃ¡dÃ¡ se do jednoho adresÃ¡Å™e nebo do adresÃ¡Å™ovÃ© struktury podle typu znÃ¡mky. Cesta se uklÃ¡dÃ¡ do databÃ¡ze v `file_path` sloupci.

Tento pÅ™Ã­stup mÃ¡ nÄ›kolik problÃ©mÅ¯: (1) co kdyÅ¾ dva uÅ¾ivatelÃ© nahrajÃ­ stejnÃ½ sken s rÅ¯znÃ½mi jmÃ©ny? UloÅ¾Ã­ se dvakrÃ¡t a ztratÃ­me mÃ­sto. (2) co kdyÅ¾ zmÄ›nÃ­me naming convention nebo pÅ™esuneme soubory do jinÃ©ho adresÃ¡Å™e? MusÃ­me updatovat tisÃ­ce zÃ¡znamÅ¯ v databÃ¡zi. (3) jak zajistit Å¾e file names jsou unique? MusÃ­me generovat artificial IDs nebo checkovat kolize. (4) jak efektivnÄ› uklÃ¡dat miliony souborÅ¯? Jeden directory s milionem souborÅ¯ mÃ¡ Å¡patnou performance.

### SHA256 jako identifikÃ¡tor

SHA256 hash je 256-bitovÃ© (64 hex znakÅ¯) ÄÃ­slo kterÃ© prakticky jednoznaÄnÄ› identifikuje obsah souboru. PravdÄ›podobnost kolize (dva rÅ¯znÃ© soubory majÃ­ stejnÃ½ hash) je astronomicky nÃ­zkÃ¡ - mÃ©nÄ› neÅ¾ Å¾e tÄ› zasÃ¡hne asteroid. Pro praktickÃ© ÃºÄely mÅ¯Å¾eme povaÅ¾ovat SHA256 za unique identifikÃ¡tor.

KdyÅ¾ pouÅ¾ijeme SHA256 jako identifikÃ¡tor souboru, Å™eÅ¡Ã­me problÃ©m (1): dva uÅ¾ivatelÃ© kteÅ™Ã­ nahrajÃ­ STEJNÃ sken (byte-by-byte identickÃ½) dostanou STEJNÃ hash. SystÃ©m poznÃ¡ Å¾e jde o duplicitu a neuloÅ¾Ã­ soubor dvakrÃ¡t. V databÃ¡zi vytvoÅ™Ã­ dva zÃ¡znamy v `user_uploads` (kaÅ¾dÃ½ uÅ¾ivatel "vlastnÃ­" svÅ¯j upload), ale v `reference_front` a v storage je jen jeden zÃ¡znam.

### 256 subdirectories strategie

UklÃ¡dat milion souborÅ¯ do jednoho adresÃ¡Å™e mÃ¡ Å¡patnou performance - filesystÃ©my nejsou optimalizovanÃ© pro tolik souborÅ¯ v jednom directory. Å˜eÅ¡enÃ­: rozdÄ›lit soubory do subdirectories.

PouÅ¾Ã­vÃ¡me prvnÃ­ 2 znaky SHA256 hashu (00 aÅ¾ ff) jako nÃ¡zev subdirectory. To vytvÃ¡Å™Ã­ 256 subdirectories a soubory se rovnomÄ›rnÄ› rozdÄ›lÃ­ mezi nÄ› (SHA256 je cryptographically random). PÅ™i milionu souborÅ¯ bude v kaÅ¾dÃ©m subdirectory prÅ¯mÄ›rnÄ› ~4000 souborÅ¯, coÅ¾ je vÃ½bornÃ¡ performance.

DalÅ¡Ã­ vÃ½hoda: strategie je deterministickÃ¡. KdyÅ¾ mÃ¡me hash `abc123...`, vÃ­me Å¾e soubor je v `ab/abc123..._front.jpg`. NemusÃ­me hledat, nemusÃ­me indexovat, prostÄ› rekonstruujeme cestu.

### Path reconstruction vs storage

Rozhodli jsme se NEUKLÃDAT cestu k souboru do databÃ¡ze (`file_path = NULL`). MÃ­sto toho ji rekonstruujeme z SHA256 hashu kdyÅ¾ potÅ™ebujeme:

```python
def get_scan_path(sha256: str, file_type: str, env: str) -> Path:
    root = Path.home() / 'ProjektHradcany' / env / 'gt_data' / 'scans'
    subdir = sha256[:2]  # PrvnÃ­ 2 znaky
    filename = f"{sha256}_{file_type}.jpg"
    return root / subdir / filename
```

To nÃ¡m dÃ¡vÃ¡ flexibilitu: mÅ¯Å¾eme zmÄ›nit root path (pÅ™esunout storage na jinÃ½ disk, do cloudu) bez update databÃ¡ze. StaÄÃ­ zmÄ›nit funkci `get_scan_path()` a vÅ¡echno funguje. TakÃ© uÅ¡etÅ™Ã­me mÃ­sto v databÃ¡zi - mÃ­sto ~100 znakÅ¯ cesty uklÃ¡dÃ¡me jen 64 znakÅ¯ hash.

---

## ğŸ’¡ DÅ®SLEDKY

### AutomatickÃ¡ deduplication

KdyÅ¾ uÅ¾ivatel nahraje sken, systÃ©m vypoÄÃ­tÃ¡ SHA256 hash a zkontroluje jestli uÅ¾ existuje v databÃ¡zi:

```python
file_sha256 = compute_sha256(uploaded_file)
existing = db.execute(
    "SELECT id FROM reference_front WHERE file_sha256 = ?",
    (file_sha256,)
).fetchone()

if existing:
    # Duplicita - sken uÅ¾ existuje
    return {'status': 'duplicate', 'scan_id': existing['id']}
else:
    # NovÃ½ sken - uloÅ¾ soubor a vytvoÅ™ zÃ¡znam
    save_file(uploaded_file, file_sha256)
    scan_id = insert_scan(file_sha256, ...)
    return {'status': 'new', 'scan_id': scan_id}
```

Toto je elegantnÃ­ Å™eÅ¡enÃ­ - nemusÃ­me porovnÃ¡vat soubory pixel-by-pixel, staÄÃ­ porovnat hashe. A protoÅ¾e hash poÄÃ­tÃ¡me z originÃ¡lu, garantujeme Å¾e dva stejnÃ© originÃ¡ly budou mÃ­t stejnÃ½ hash.

### Multi-user ownership

Deduplication je multi-user safe. KdyÅ¾ uÅ¾ivatel A nahraje sken `abc123...` a pozdÄ›ji uÅ¾ivatel B nahraje STEJNÃ sken:

**V databÃ¡zi:**
```sql
-- reference_front (jeden zÃ¡znam)
id=150, file_sha256='abc123...', confirmed=1, ...

-- user_uploads (dva zÃ¡znamy)
id=1, scan_id=150, uploaded_by='userA'
id=2, scan_id=150, uploaded_by='userB'
```

**V storage:**
```
gt_data/scans/ab/abc123..._front.jpg  (jeden soubor)
```

KaÅ¾dÃ½ uÅ¾ivatel vidÃ­ "svÅ¯j" upload ve svÃ©m seznamu (dÃ­ky zÃ¡znamu v `user_uploads`), ale fyzicky je uloÅ¾en jen jeden soubor. KdyÅ¾ uÅ¾ivatel A smaÅ¾e svÅ¯j view, zÃ¡znam v `user_uploads` se smaÅ¾e, ale soubor zÅ¯stane (protoÅ¾e ho jeÅ¡tÄ› vlastnÃ­ user B).

### Scalability

256 subdirectories umoÅ¾Åˆuje Å¡kÃ¡lovat na miliony souborÅ¯. PÅ™i 1 milionu souborÅ¯:
- PrÅ¯mÄ›rnÄ› ~4000 souborÅ¯ per subdirectory
- Filesystem performance zÅ¯stÃ¡vÃ¡ dobrÃ¡
- Lookup je O(1) - hash â†’ subdirectory â†’ soubor

Pokud bychom v budoucnu potÅ™ebovali jeÅ¡tÄ› lepÅ¡Ã­ scalability (desÃ­tky milionÅ¯ souborÅ¯), mÅ¯Å¾eme pÅ™idat dalÅ¡Ã­ ÃºroveÅˆ: `<first2>/<next2>/<sha256>_front.jpg` (65,536 subdirectories).

### Flexibilita storage

ProtoÅ¾e cesty rekonstruujeme z hashe, mÅ¯Å¾eme zmÄ›nit storage strategii bez migrace databÃ¡ze:

**ZmÄ›na root path:**
```python
# PÅ¯vodnÄ›:
root = Path.home() / 'ProjektHradcany' / env / 'gt_data' / 'scans'

# NovÃ½ disk:
root = Path('/mnt/fast_ssd') / 'hradcany_storage'
```

**Cloud storage (budoucnost):**
```python
# S3 bucket:
def get_scan_url(sha256: str, file_type: str) -> str:
    return f"s3://hradcany-prod/{sha256[:2]}/{sha256}_{file_type}.jpg"
```

DatabÃ¡ze zÅ¯stÃ¡vÃ¡ stejnÃ¡, jen zmÄ›nÃ­me jak konstruujeme cesty/URLs.

---

## ğŸ”§ TECHNICKÃ‰ DETAILY

### VÃ½poÄet SHA256

```python
import hashlib

def compute_sha256(file_path: Path) -> str:
    """
    VypoÄÃ­tÃ¡ SHA256 hash souboru.
    ÄŒte po chunkcÃ­ch pro memory efficiency.
    """
    sha = hashlib.sha256()
    with open(file_path, 'rb') as f:
        while chunk := f.read(8192):
            sha.update(chunk)
    return sha.hexdigest()  # 64 hex znakÅ¯
```

KRITICKÃ‰: PoÄÃ­tÃ¡me hash z ORIGINÃLU, ne z transformacÃ­ (warp)! Viz `tasks/bug_uc1_file_storage.md` pro znÃ¡mÃ½ bug kde souÄasnÃ¡ implementace hashuje warp.

### Storage struktura

```
~/ProjektHradcany/dev/gt_data/scans/
â”œâ”€â”€ 00/
â”‚   â”œâ”€â”€ 00a1b2c3..._front.jpg
â”‚   â”œâ”€â”€ 00a1b2c3..._back.jpg
â”‚   â””â”€â”€ 00d4e5f6..._front.jpg
â”œâ”€â”€ 01/
â”‚   â””â”€â”€ 01234567..._front.jpg
â”œâ”€â”€ 02/
...
â”œâ”€â”€ fe/
â””â”€â”€ ff/
    â””â”€â”€ ffabcdef..._front.jpg
```

KaÅ¾dÃ½ subdirectory (00 aÅ¾ ff) obsahuje soubory jejichÅ¾ hash zaÄÃ­nÃ¡ tÄ›mito dvÄ›ma znaky. V kaÅ¾dÃ©m souboru je suffix `_front`, `_back`, `_cert`, nebo `_block` podle typu.

### File types

- `_front.jpg` - PÅ™ednÃ­ strana znÃ¡mky (REQUIRED, primary)
- `_back.jpg` - ZadnÃ­ strana (OPTIONAL, pro vodotisk check)
- `_cert.pdf` - CertifikÃ¡t autenticity (OPTIONAL, pro auto-approval)
- `_block.jpg` - BlokovÃ¡ ÄtveÅ™ice (OPTIONAL, pro plate reconstruction)

---

## ğŸ”— SOUVISLOSTI

**PouÅ¾Ã­vÃ¡no v:**
- UC-1 workflow - Deduplication check, file storage
- UC-4 batch import - Bulk file handling

**TechnickÃ¡ dokumentace:**
- [base/file_storage_architecture.md](../base/file_storage_architecture.md) - Detaily storage systÃ©mu

**DalÅ¡Ã­ rozhodnutÃ­:**
- [decisions/uc1_workflow.md](./uc1_workflow.md) - Jak UC-1 pouÅ¾Ã­vÃ¡ SHA256 storage
- [decisions/schema_v3_1_0_nullable_columns.md](./schema_v3_1_0_nullable_columns.md) - ProÄ file_path je nullable

**ZnÃ¡mÃ½ bug:**
- [tasks/bug_uc1_file_storage.md](../tasks/bug_uc1_file_storage.md) - SHA256 musÃ­ bÃ½t z originÃ¡lu, ne warpu!

---

**PoslednÃ­ aktualizace:** 2026-01-09  
**Autor:** Milan + Claude  
**Status:** âœ… ACTIVE

---
